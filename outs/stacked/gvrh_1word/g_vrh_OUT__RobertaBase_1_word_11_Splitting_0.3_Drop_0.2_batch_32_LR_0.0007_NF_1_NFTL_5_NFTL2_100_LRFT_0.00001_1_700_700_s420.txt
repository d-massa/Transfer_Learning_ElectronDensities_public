0.3 0.2 32 0.0007 1 5 100 g_vrh

You are running the InceptionV3 model, with Splitting_test_and_hold=0.3, Drop=0.2, batch=32, LR=0.0007.


---------------
DATA PREPARATION
---------------

The length of training, testing, and holdout dataset is: 414 89 89 respectively
(592, 186, 186, 3)
Training fold 1...
0.0007
Model: "my_image_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 186, 186, 3)]     0         
                                                                 
 inception_v3 (Functional)   (None, 4, 4, 2048)        21802784  
                                                                 
 global_average_pooling2d (G  (None, 2048)             0         
 lobalAveragePooling2D)                                          
                                                                 
 dense_1_image (Dense)       (None, 1024)              2098176   
                                                                 
 bn_1_image (BatchNormalizat  (None, 1024)             4096      
 ion)                                                            
                                                                 
 dropout_1_image (Dropout)   (None, 1024)              0         
                                                                 
 dense_2_image (Dense)       (None, 512)               524800    
                                                                 
 bn_2_image (BatchNormalizat  (None, 512)              2048      
 ion)                                                            
                                                                 
 dropout_2_image (Dropout)   (None, 512)               0         
                                                                 
 dense_3_image (Dense)       (None, 256)               131328    
                                                                 
 bn_3_image (BatchNormalizat  (None, 256)              1024      
 ion)                                                            
                                                                 
 dropout_3_image (Dropout)   (None, 256)               0         
                                                                 
 dense_4_image (Dense)       (None, 1)                 257       
                                                                 
=================================================================
Total params: 24,564,513
Trainable params: 2,758,145
Non-trainable params: 21,806,368
_________________________________________________________________
None

Search: Running Trial #1

Value             |Best Value So Far |Hyperparameter
0.0007            |0.0007            |learning_rate

0.0007
Model: "my_image_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 186, 186, 3)]     0         
                                                                 
 inception_v3 (Functional)   (None, 4, 4, 2048)        21802784  
                                                                 
 global_average_pooling2d (G  (None, 2048)             0         
 lobalAveragePooling2D)                                          
                                                                 
 dense_1_image (Dense)       (None, 1024)              2098176   
                                                                 
 bn_1_image (BatchNormalizat  (None, 1024)             4096      
 ion)                                                            
                                                                 
 dropout_1_image (Dropout)   (None, 1024)              0         
                                                                 
 dense_2_image (Dense)       (None, 512)               524800    
                                                                 
 bn_2_image (BatchNormalizat  (None, 512)              2048      
 ion)                                                            
                                                                 
 dropout_2_image (Dropout)   (None, 512)               0         
                                                                 
 dense_3_image (Dense)       (None, 256)               131328    
                                                                 
 bn_3_image (BatchNormalizat  (None, 256)              1024      
 ion)                                                            
                                                                 
 dropout_3_image (Dropout)   (None, 256)               0         
                                                                 
 dense_4_image (Dense)       (None, 1)                 257       
                                                                 
=================================================================
Total params: 24,564,513
Trainable params: 2,758,145
Non-trainable params: 21,806,368
_________________________________________________________________
None
 1/15 [=>............................] - ETA: 1:12 - loss: 2.6657 5/15 [=========>....................] - ETA: 0s - loss: 3.1119   9/15 [=================>............] - ETA: 0s - loss: 3.115113/15 [=========================>....] - ETA: 0s - loss: 2.774915/15 [==============================] - ETA: 0s - loss: 2.760615/15 [==============================] - 9s 240ms/step - loss: 2.7606 - val_loss: 5.0841
[2K[2KTrial 1 Complete [00h 00m 09s]
val_loss: 5.084068298339844

Best val_loss So Far: 5.084068298339844
Total elapsed time: 00h 00m 09s
Best Learning Rate for fold 1 : 0.0007
0.0007
Model: "my_image_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 186, 186, 3)]     0         
                                                                 
 inception_v3 (Functional)   (None, 4, 4, 2048)        21802784  
                                                                 
 global_average_pooling2d_1   (None, 2048)             0         
 (GlobalAveragePooling2D)                                        
                                                                 
 dense_1_image (Dense)       (None, 1024)              2098176   
                                                                 
 bn_1_image (BatchNormalizat  (None, 1024)             4096      
 ion)                                                            
                                                                 
 dropout_1_image (Dropout)   (None, 1024)              0         
                                                                 
 dense_2_image (Dense)       (None, 512)               524800    
                                                                 
 bn_2_image (BatchNormalizat  (None, 512)              2048      
 ion)                                                            
                                                                 
 dropout_2_image (Dropout)   (None, 512)               0         
                                                                 
 dense_3_image (Dense)       (None, 256)               131328    
                                                                 
 bn_3_image (BatchNormalizat  (None, 256)              1024      
 ion)                                                            
                                                                 
 dropout_3_image (Dropout)   (None, 256)               0         
                                                                 
 dense_4_image (Dense)       (None, 1)                 257       
                                                                 
=================================================================
Total params: 24,564,513
Trainable params: 2,758,145
Non-trainable params: 21,806,368
_________________________________________________________________
None
Model: "my_image_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 186, 186, 3)]     0         
                                                                 
 inception_v3 (Functional)   (None, 4, 4, 2048)        21802784  
                                                                 
 global_average_pooling2d_1   (None, 2048)             0         
 (GlobalAveragePooling2D)                                        
                                                                 
 dense_1_image (Dense)       (None, 1024)              2098176   
                                                                 
 bn_1_image (BatchNormalizat  (None, 1024)             4096      
 ion)                                                            
                                                                 
 dropout_1_image (Dropout)   (None, 1024)              0         
                                                                 
 dense_2_image (Dense)       (None, 512)               524800    
                                                                 
 bn_2_image (BatchNormalizat  (None, 512)              2048      
 ion)                                                            
                                                                 
 dropout_2_image (Dropout)   (None, 512)               0         
                                                                 
 dense_3_image (Dense)       (None, 256)               131328    
                                                                 
 bn_3_image (BatchNormalizat  (None, 256)              1024      
 ion)                                                            
                                                                 
 dropout_3_image (Dropout)   (None, 256)               0         
                                                                 
 dense_4_image (Dense)       (None, 1)                 257       
                                                                 
=================================================================
Total params: 24,564,513
Trainable params: 2,758,145
Non-trainable params: 21,806,368
_________________________________________________________________
FINAL MODEL: None
Epoch 1/700
 1/15 [=>............................] - ETA: 45s - loss: 2.0983 5/15 [=========>....................] - ETA: 0s - loss: 3.0517  9/15 [=================>............] - ETA: 0s - loss: 2.767013/15 [=========================>....] - ETA: 0s - loss: 2.4670
Epoch 1: val_loss improved from inf to 5.53304, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/KFold/fold_0.hdf5
15/15 [==============================] - 9s 419ms/step - loss: 2.3621 - val_loss: 5.5330
Epoch 2/700
 1/15 [=>............................] - ETA: 0s - loss: 2.1047 5/15 [=========>....................] - ETA: 0s - loss: 1.8999 9/15 [=================>............] - ETA: 0s - loss: 1.692913/15 [=========================>....] - ETA: 0s - loss: 1.6572
Epoch 2: val_loss improved from 5.53304 to 5.03149, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/KFold/fold_0.hdf5
15/15 [==============================] - 5s 349ms/step - loss: 1.5881 - val_loss: 5.0315
Epoch 3/700
 1/15 [=>............................] - ETA: 0s - loss: 0.8511 5/15 [=========>....................] - ETA: 0s - loss: 1.0314 9/15 [=================>............] - ETA: 0s - loss: 1.000313/15 [=========================>....] - ETA: 0s - loss: 1.0136
Epoch 3: val_loss did not improve from 5.03149
15/15 [==============================] - 3s 237ms/step - loss: 0.9852 - val_loss: 5.8084
Epoch 4/700
 1/15 [=>............................] - ETA: 0s - loss: 0.5538 5/15 [=========>....................] - ETA: 0s - loss: 0.7862 9/15 [=================>............] - ETA: 0s - loss: 0.856313/15 [=========================>....] - ETA: 0s - loss: 0.9077
Epoch 4: val_loss did not improve from 5.03149
15/15 [==============================] - 3s 238ms/step - loss: 0.8895 - val_loss: 5.5385
Epoch 5/700
 1/15 [=>............................] - ETA: 0s - loss: 0.7538 5/15 [=========>....................] - ETA: 0s - loss: 0.7276 9/15 [=================>............] - ETA: 0s - loss: 0.738813/15 [=========================>....] - ETA: 0s - loss: 0.7024
Epoch 5: val_loss did not improve from 5.03149
15/15 [==============================] - 3s 239ms/step - loss: 0.6866 - val_loss: 5.4077
Epoch 6/700
 1/15 [=>............................] - ETA: 0s - loss: 0.5142 5/15 [=========>....................] - ETA: 0s - loss: 0.6086 9/15 [=================>............] - ETA: 0s - loss: 0.678313/15 [=========================>....] - ETA: 0s - loss: 0.6631
Epoch 6: val_loss did not improve from 5.03149
15/15 [==============================] - 3s 236ms/step - loss: 0.6670 - val_loss: 5.2847
Epoch 7/700
 1/15 [=>............................] - ETA: 0s - loss: 0.4267 5/15 [=========>....................] - ETA: 0s - loss: 0.5959 9/15 [=================>............] - ETA: 0s - loss: 0.641613/15 [=========================>....] - ETA: 0s - loss: 0.6319
Epoch 7: val_loss did not improve from 5.03149
15/15 [==============================] - 3s 239ms/step - loss: 0.6235 - val_loss: 5.1832
Epoch 8/700
 1/15 [=>............................] - ETA: 0s - loss: 0.5530 5/15 [=========>....................] - ETA: 0s - loss: 0.7275 9/15 [=================>............] - ETA: 0s - loss: 0.735413/15 [=========================>....] - ETA: 0s - loss: 0.6744
Epoch 8: val_loss improved from 5.03149 to 4.93979, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/KFold/fold_0.hdf5
15/15 [==============================] - 5s 356ms/step - loss: 0.6505 - val_loss: 4.9398
Epoch 9/700
 1/15 [=>............................] - ETA: 0s - loss: 0.5548 5/15 [=========>....................] - ETA: 0s - loss: 0.5294 9/15 [=================>............] - ETA: 0s - loss: 0.573412/15 [=======================>......] - ETA: 0s - loss: 0.5909
Epoch 9: val_loss did not improve from 4.93979
15/15 [==============================] - 3s 242ms/step - loss: 0.6019 - val_loss: 4.9901
Epoch 10/700
 1/15 [=>............................] - ETA: 0s - loss: 0.7528 5/15 [=========>....................] - ETA: 0s - loss: 0.5300 9/15 [=================>............] - ETA: 0s - loss: 0.509213/15 [=========================>....] - ETA: 0s - loss: 0.5496
Epoch 10: val_loss improved from 4.93979 to 4.75321, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/KFold/fold_0.hdf5
15/15 [==============================] - 5s 361ms/step - loss: 0.5503 - val_loss: 4.7532
Epoch 11/700
 1/15 [=>............................] - ETA: 0s - loss: 0.5032 5/15 [=========>....................] - ETA: 0s - loss: 0.4153 9/15 [=================>............] - ETA: 0s - loss: 0.477213/15 [=========================>....] - ETA: 0s - loss: 0.4792
Epoch 11: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 235ms/step - loss: 0.4813 - val_loss: 4.7778
Epoch 12/700
 1/15 [=>............................] - ETA: 0s - loss: 0.4076 5/15 [=========>....................] - ETA: 0s - loss: 0.4134 9/15 [=================>............] - ETA: 0s - loss: 0.428813/15 [=========================>....] - ETA: 0s - loss: 0.4426
Epoch 12: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 236ms/step - loss: 0.4560 - val_loss: 4.9129
Epoch 13/700
 1/15 [=>............................] - ETA: 0s - loss: 0.2849 5/15 [=========>....................] - ETA: 0s - loss: 0.5072 9/15 [=================>............] - ETA: 0s - loss: 0.536213/15 [=========================>....] - ETA: 0s - loss: 0.5156
Epoch 13: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 236ms/step - loss: 0.5042 - val_loss: 4.9153
Epoch 14/700
 1/15 [=>............................] - ETA: 0s - loss: 0.3430 5/15 [=========>....................] - ETA: 0s - loss: 0.3786 9/15 [=================>............] - ETA: 0s - loss: 0.411013/15 [=========================>....] - ETA: 0s - loss: 0.4613
Epoch 14: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 232ms/step - loss: 0.4508 - val_loss: 4.9468
Epoch 15/700
 1/15 [=>............................] - ETA: 0s - loss: 0.4600 5/15 [=========>....................] - ETA: 0s - loss: 0.5010 8/15 [===============>..............] - ETA: 0s - loss: 0.463812/15 [=======================>......] - ETA: 0s - loss: 0.4967
Epoch 15: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 240ms/step - loss: 0.4622 - val_loss: 4.9940
Epoch 16/700
 1/15 [=>............................] - ETA: 0s - loss: 0.3191 5/15 [=========>....................] - ETA: 0s - loss: 0.4769 9/15 [=================>............] - ETA: 0s - loss: 0.421213/15 [=========================>....] - ETA: 0s - loss: 0.4153
Epoch 16: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 235ms/step - loss: 0.4188 - val_loss: 4.9436
Epoch 17/700
 1/15 [=>............................] - ETA: 0s - loss: 0.4722 5/15 [=========>....................] - ETA: 0s - loss: 0.4486 9/15 [=================>............] - ETA: 0s - loss: 0.437813/15 [=========================>....] - ETA: 0s - loss: 0.4142
Epoch 17: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 237ms/step - loss: 0.4130 - val_loss: 4.8784
Epoch 18/700
 1/15 [=>............................] - ETA: 0s - loss: 0.4487 5/15 [=========>....................] - ETA: 0s - loss: 0.3913 9/15 [=================>............] - ETA: 0s - loss: 0.345013/15 [=========================>....] - ETA: 0s - loss: 0.3584
Epoch 18: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 229ms/step - loss: 0.3607 - val_loss: 4.8502
Epoch 19/700
 1/15 [=>............................] - ETA: 0s - loss: 0.3095 5/15 [=========>....................] - ETA: 0s - loss: 0.3466 9/15 [=================>............] - ETA: 0s - loss: 0.325513/15 [=========================>....] - ETA: 0s - loss: 0.3458
Epoch 19: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 237ms/step - loss: 0.3498 - val_loss: 4.7564
Epoch 20/700
 1/15 [=>............................] - ETA: 0s - loss: 0.1568 5/15 [=========>....................] - ETA: 0s - loss: 0.2350 9/15 [=================>............] - ETA: 0s - loss: 0.288113/15 [=========================>....] - ETA: 0s - loss: 0.2756
Epoch 20: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 237ms/step - loss: 0.2902 - val_loss: 4.9208
Epoch 21/700
 1/15 [=>............................] - ETA: 0s - loss: 0.3495 5/15 [=========>....................] - ETA: 0s - loss: 0.3622 9/15 [=================>............] - ETA: 0s - loss: 0.319413/15 [=========================>....] - ETA: 0s - loss: 0.3145
Epoch 21: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 238ms/step - loss: 0.3205 - val_loss: 4.9051
Epoch 22/700
 1/15 [=>............................] - ETA: 0s - loss: 0.2687 5/15 [=========>....................] - ETA: 0s - loss: 0.3164 9/15 [=================>............] - ETA: 0s - loss: 0.285313/15 [=========================>....] - ETA: 0s - loss: 0.2953
Epoch 22: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 234ms/step - loss: 0.2883 - val_loss: 4.9543
Epoch 23/700
 1/15 [=>............................] - ETA: 0s - loss: 0.3258 5/15 [=========>....................] - ETA: 0s - loss: 0.3447 9/15 [=================>............] - ETA: 0s - loss: 0.301613/15 [=========================>....] - ETA: 0s - loss: 0.3062
Epoch 23: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 234ms/step - loss: 0.3075 - val_loss: 4.9308
Epoch 24/700
 1/15 [=>............................] - ETA: 0s - loss: 0.1996 5/15 [=========>....................] - ETA: 0s - loss: 0.2699 9/15 [=================>............] - ETA: 0s - loss: 0.306613/15 [=========================>....] - ETA: 0s - loss: 0.2905
Epoch 24: val_loss did not improve from 4.75321
15/15 [==============================] - 3s 230ms/step - loss: 0.2839 - val_loss: 5.0132
Epoch 25/700
 1/15 [=>............................] - ETA: 0s - loss: 0.2222 5/15 [=========>....................] - ETA: 0s - loss: 0.2771 9/15 [=================>............] - ETA: 0s - loss: 0.254313/15 [=========================>....] - ETA: 0s - loss: 0.2741
Epoch 25: val_loss did not improve from 4.75321
15/15 [==============================] - 4s 251ms/step - loss: 0.2709 - val_loss: 4.8108
1/3 [=========>....................] - ETA: 2s - loss: 0.26333/3 [==============================] - 1s 11ms/step - loss: 2.9783
Fold 1 Loss: 2.978295087814331
Average Loss: 2.978295087814331

PERFORMANCES of the pretrained model, no fine-tuning

1/3 [=========>....................] - ETA: 0s - loss: 0.28483/3 [==============================] - 0s 12ms/step - loss: 0.2538
1/3 [=========>....................] - ETA: 1s3/3 [==============================] - 1s 11ms/step
Test Loss (MSE): 0.2538205683231354
Mean Squared Error (MSE): 0.2538206
Mean Absolute Error (MAE): 0.4124342
R-squared (R2) Score: -3.8826058402114656
 1/13 [=>............................] - ETA: 0s 7/13 [===============>..............] - ETA: 0s12/13 [==========================>...] - ETA: 0s13/13 [==============================] - ETA: 0s13/13 [==============================] - 0s 16ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 12ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 12ms/step
Training rmse: 0.96  and Testing rmse: 0.5 and Hold rmse: 1.73
Training R2: -0.16  and Testing R2: -3.88 and Hold R2: -0.04

____________
FINE-TUNING
____________

Epoch 1/700
 1/13 [=>............................] - ETA: 34s - loss: 0.3689 5/13 [==========>...................] - ETA: 0s - loss: 0.5363  9/13 [===================>..........] - ETA: 0s - loss: 1.425113/13 [==============================] - ETA: 0s - loss: 1.1529
Epoch 1: val_loss improved from inf to 0.19684, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 6s 227ms/step - loss: 1.1529 - val_loss: 0.1968
Epoch 2/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4058 5/13 [==========>...................] - ETA: 0s - loss: 0.4850 9/13 [===================>..........] - ETA: 0s - loss: 0.463813/13 [==============================] - ETA: 0s - loss: 1.0666
Epoch 2: val_loss improved from 0.19684 to 0.14638, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 148ms/step - loss: 1.0666 - val_loss: 0.1464
Epoch 3/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2716 5/13 [==========>...................] - ETA: 0s - loss: 0.3320 9/13 [===================>..........] - ETA: 0s - loss: 1.376213/13 [==============================] - ETA: 0s - loss: 1.1106
Epoch 3: val_loss improved from 0.14638 to 0.12359, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 3s 267ms/step - loss: 1.1106 - val_loss: 0.1236
Epoch 4/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5575 5/13 [==========>...................] - ETA: 0s - loss: 0.5020 9/13 [===================>..........] - ETA: 0s - loss: 1.373913/13 [==============================] - ETA: 0s - loss: 1.1162
Epoch 4: val_loss improved from 0.12359 to 0.10704, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 161ms/step - loss: 1.1162 - val_loss: 0.1070
Epoch 5/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4825 5/13 [==========>...................] - ETA: 0s - loss: 0.4728 9/13 [===================>..........] - ETA: 0s - loss: 0.524913/13 [==============================] - ETA: 0s - loss: 1.1755
Epoch 5: val_loss improved from 0.10704 to 0.08882, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.1755 - val_loss: 0.0888
Epoch 6/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2996 5/13 [==========>...................] - ETA: 0s - loss: 0.4549 9/13 [===================>..........] - ETA: 0s - loss: 0.498113/13 [==============================] - ETA: 0s - loss: 1.1150
Epoch 6: val_loss improved from 0.08882 to 0.08151, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.1150 - val_loss: 0.0815
Epoch 7/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3308 5/13 [==========>...................] - ETA: 0s - loss: 0.5852 9/13 [===================>..........] - ETA: 0s - loss: 1.485013/13 [==============================] - ETA: 0s - loss: 1.1788
Epoch 7: val_loss improved from 0.08151 to 0.07971, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 160ms/step - loss: 1.1788 - val_loss: 0.0797
Epoch 8/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5355 5/13 [==========>...................] - ETA: 0s - loss: 0.3902 9/13 [===================>..........] - ETA: 0s - loss: 0.407413/13 [==============================] - ETA: 0s - loss: 1.0352
Epoch 8: val_loss improved from 0.07971 to 0.07631, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 148ms/step - loss: 1.0352 - val_loss: 0.0763
Epoch 9/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4999 5/13 [==========>...................] - ETA: 0s - loss: 1.9914 9/13 [===================>..........] - ETA: 0s - loss: 1.286413/13 [==============================] - ETA: 0s - loss: 1.0222
Epoch 9: val_loss improved from 0.07631 to 0.07316, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.0222 - val_loss: 0.0732
Epoch 10/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4479 5/13 [==========>...................] - ETA: 0s - loss: 1.7958 9/13 [===================>..........] - ETA: 0s - loss: 1.260713/13 [==============================] - ETA: 0s - loss: 1.0375
Epoch 10: val_loss improved from 0.07316 to 0.07084, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 148ms/step - loss: 1.0375 - val_loss: 0.0708
Epoch 11/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3130 5/13 [==========>...................] - ETA: 0s - loss: 0.3714 9/13 [===================>..........] - ETA: 0s - loss: 0.458113/13 [==============================] - ETA: 0s - loss: 1.1520
Epoch 11: val_loss improved from 0.07084 to 0.06808, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 149ms/step - loss: 1.1520 - val_loss: 0.0681
Epoch 12/700
 1/13 [=>............................] - ETA: 0s - loss: 9.8888 5/13 [==========>...................] - ETA: 0s - loss: 2.3499 9/13 [===================>..........] - ETA: 0s - loss: 1.510713/13 [==============================] - ETA: 0s - loss: 1.1774
Epoch 12: val_loss improved from 0.06808 to 0.06563, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.1774 - val_loss: 0.0656
Epoch 13/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3398 5/13 [==========>...................] - ETA: 0s - loss: 1.7614 9/13 [===================>..........] - ETA: 0s - loss: 1.234113/13 [==============================] - ETA: 0s - loss: 0.9803
Epoch 13: val_loss improved from 0.06563 to 0.06551, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 0.9803 - val_loss: 0.0655
Epoch 14/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4044 5/13 [==========>...................] - ETA: 0s - loss: 0.4883 9/13 [===================>..........] - ETA: 0s - loss: 0.449313/13 [==============================] - ETA: 0s - loss: 1.0256
Epoch 14: val_loss improved from 0.06551 to 0.06528, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.0256 - val_loss: 0.0653
Epoch 15/700
 1/13 [=>............................] - ETA: 0s - loss: 9.5755 5/13 [==========>...................] - ETA: 0s - loss: 2.3463 9/13 [===================>..........] - ETA: 0s - loss: 1.496713/13 [==============================] - ETA: 0s - loss: 1.1913
Epoch 15: val_loss did not improve from 0.06528
13/13 [==============================] - 0s 19ms/step - loss: 1.1913 - val_loss: 0.0656
Epoch 16/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4023 5/13 [==========>...................] - ETA: 0s - loss: 2.1933 9/13 [===================>..........] - ETA: 0s - loss: 1.459413/13 [==============================] - ETA: 0s - loss: 1.1429
Epoch 16: val_loss improved from 0.06528 to 0.06523, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 147ms/step - loss: 1.1429 - val_loss: 0.0652
Epoch 17/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3932 5/13 [==========>...................] - ETA: 0s - loss: 1.8545 9/13 [===================>..........] - ETA: 0s - loss: 1.203013/13 [==============================] - ETA: 0s - loss: 0.9780
Epoch 17: val_loss improved from 0.06523 to 0.06477, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 144ms/step - loss: 0.9780 - val_loss: 0.0648
Epoch 18/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3429 5/13 [==========>...................] - ETA: 0s - loss: 0.4329 9/13 [===================>..........] - ETA: 0s - loss: 0.428813/13 [==============================] - ETA: 0s - loss: 0.9468
Epoch 18: val_loss improved from 0.06477 to 0.06467, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 148ms/step - loss: 0.9468 - val_loss: 0.0647
Epoch 19/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3457 5/13 [==========>...................] - ETA: 0s - loss: 0.4177 9/13 [===================>..........] - ETA: 0s - loss: 0.448913/13 [==============================] - ETA: 0s - loss: 1.0621
Epoch 19: val_loss improved from 0.06467 to 0.06402, saving model to results/RobertaBase_g_vrh_1_word/image_only/saved_models/finetuned.hdf5
13/13 [==============================] - 2s 149ms/step - loss: 1.0621 - val_loss: 0.0640
Epoch 20/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5335 5/13 [==========>...................] - ETA: 0s - loss: 0.4422 9/13 [===================>..........] - ETA: 0s - loss: 1.511013/13 [==============================] - ETA: 0s - loss: 1.1790
Epoch 20: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 1.1790 - val_loss: 0.0641
Epoch 21/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5204 5/13 [==========>...................] - ETA: 0s - loss: 0.4323 9/13 [===================>..........] - ETA: 0s - loss: 1.205113/13 [==============================] - ETA: 0s - loss: 0.9729
Epoch 21: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9729 - val_loss: 0.0661
Epoch 22/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5345 5/13 [==========>...................] - ETA: 0s - loss: 0.4919 9/13 [===================>..........] - ETA: 0s - loss: 1.294313/13 [==============================] - ETA: 0s - loss: 1.0137
Epoch 22: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 1.0137 - val_loss: 0.0663
Epoch 23/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4511 5/13 [==========>...................] - ETA: 0s - loss: 0.5027 9/13 [===================>..........] - ETA: 0s - loss: 1.216413/13 [==============================] - ETA: 0s - loss: 0.9775
Epoch 23: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9775 - val_loss: 0.0657
Epoch 24/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3053 5/13 [==========>...................] - ETA: 0s - loss: 0.5072 9/13 [===================>..........] - ETA: 0s - loss: 0.500913/13 [==============================] - ETA: 0s - loss: 0.9768
Epoch 24: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9768 - val_loss: 0.0670
Epoch 25/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5399 5/13 [==========>...................] - ETA: 0s - loss: 2.0092 9/13 [===================>..........] - ETA: 0s - loss: 1.333313/13 [==============================] - ETA: 0s - loss: 1.0753
Epoch 25: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 18ms/step - loss: 1.0753 - val_loss: 0.0669
Epoch 26/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3396 5/13 [==========>...................] - ETA: 0s - loss: 1.9904 9/13 [===================>..........] - ETA: 0s - loss: 1.339713/13 [==============================] - ETA: 0s - loss: 1.0743
Epoch 26: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 1.0743 - val_loss: 0.0663
Epoch 27/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3903 5/13 [==========>...................] - ETA: 0s - loss: 0.3603 9/13 [===================>..........] - ETA: 0s - loss: 0.374813/13 [==============================] - ETA: 0s - loss: 0.9130
Epoch 27: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9130 - val_loss: 0.0654
Epoch 28/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2846 5/13 [==========>...................] - ETA: 0s - loss: 1.8513 9/13 [===================>..........] - ETA: 0s - loss: 1.204613/13 [==============================] - ETA: 0s - loss: 0.9556
Epoch 28: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9556 - val_loss: 0.0661
Epoch 29/700
 1/13 [=>............................] - ETA: 0s - loss: 7.7325 5/13 [==========>...................] - ETA: 0s - loss: 1.9077 9/13 [===================>..........] - ETA: 0s - loss: 1.241313/13 [==============================] - ETA: 0s - loss: 0.9933
Epoch 29: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 20ms/step - loss: 0.9933 - val_loss: 0.0701
Epoch 30/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5732 5/13 [==========>...................] - ETA: 0s - loss: 0.5221 9/13 [===================>..........] - ETA: 0s - loss: 1.196613/13 [==============================] - ETA: 0s - loss: 0.9774
Epoch 30: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9774 - val_loss: 0.0715
Epoch 31/700
 1/13 [=>............................] - ETA: 0s - loss: 7.4915 5/13 [==========>...................] - ETA: 0s - loss: 1.8462 9/13 [===================>..........] - ETA: 0s - loss: 1.234913/13 [==============================] - ETA: 0s - loss: 1.0069
Epoch 31: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 1.0069 - val_loss: 0.0726
Epoch 32/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2372 5/13 [==========>...................] - ETA: 0s - loss: 1.9233 9/13 [===================>..........] - ETA: 0s - loss: 1.229813/13 [==============================] - ETA: 0s - loss: 0.9609
Epoch 32: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9609 - val_loss: 0.0729
Epoch 33/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3544 5/13 [==========>...................] - ETA: 0s - loss: 0.4825 9/13 [===================>..........] - ETA: 0s - loss: 0.425213/13 [==============================] - ETA: 0s - loss: 0.9519
Epoch 33: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 19ms/step - loss: 0.9519 - val_loss: 0.0727
Epoch 34/700
 1/13 [=>............................] - ETA: 0s - loss: 0.5224 5/13 [==========>...................] - ETA: 0s - loss: 0.3932 9/13 [===================>..........] - ETA: 0s - loss: 1.097113/13 [==============================] - ETA: 0s - loss: 0.9153
Epoch 34: val_loss did not improve from 0.06402
13/13 [==============================] - 0s 28ms/step - loss: 0.9153 - val_loss: 0.0723
!!!THE FINAL RESULTS FOR IMAGE ONLY:
 1/13 [=>............................] - ETA: 10s 6/13 [============>.................] - ETA: 0s 11/13 [========================>.....] - ETA: 0s13/13 [==============================] - 1s 10ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 10ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 11ms/step
Training rmse: 0.78  and Testing rmse: 0.25 and Hold rmse: 1.72
Training R2: 0.23  and Testing R2: -0.23 and Hold R2: -0.03

---------------
ADDING TEXT ON TOP
---------------

['Be2PtCu', 'TiWMn2', 'Ru2TiGe', 'Cs2LiInBr6', 'ScTaOs2', 'Ta2VRu', 'RbI', 'ScPd2Cd', 'Rb2TiCl6', 'Fe2TiGe', 'TlPd3O4', 'YPd2In', 'TiMoTc2', 'Pd2CdIn', 'Hf2OsRh', 'Hf2IrRh', 'LiAg2Zn', 'LiTiRh2', 'BeNbRu2', 'ScCo2Ga', 'TaC', 'AuIn2', 'MgZrIr2', 'TiWTc2', 'CaS', 'Ti2ReIr', 'ScTaRu2', 'LiBePd2', 'ScH2', 'LiIrAl2', 'LiScPt2', 'ThO2', 'YPd2Cd', 'HfWTc2', 'K2PdCl6', 'Mg2RhAg', 'Sc2RuCo', 'Fe2TiSi', 'TiIr2Zn', 'YbO', 'HK1', 'PrN', 'TaRh2Cu', 'NaMgPb2', 'ThC', 'ScVRu2', 'Cs2PtBr6', 'Ti2ReRh', 'ScRh2Al', 'Sc2RuZn', 'TiTaTc2', 'LiHf2Re', 'Na2O', 'Sc2RuCu', 'YAs', 'LiZrPt2', 'ZrC', 'MgNi2Sn', 'Cu', 'TiTaOs2', 'LiPdAu2', 'Ru2TiSi', 'LiSc2Pt', 'MgTiRh2', 'Mg2RhPd', 'Ti2MnRh', 'RbF', 'V3Re', 'LiPt2Ga', 'RbCl', 'Ta2NbIr', 'MgZrAu2', 'AuGa2', 'MgIr2Si', 'LuN', 'Cs2LiLuCl6', 'Rb2PtCl6', 'LiSc2Ir', 'MgIr2Sn', 'LiNiAl2', 'TiTaRe2', 'HoH2', 'LaMg3', 'MgRh2Al', 'MgIr2Al', 'TiCo2Zn', 'MgPd2Ga', 'CaMgHg2', 'RhNiZn2', 'Sc2ZnGa', 'Ru2AlSi', 'Ti2TcRh', 'Rb2PtI6', 'ScPd2In', 'LiCo2Ge', 'ScIr2Al', 'Sc2IrCo', 'V2TcOs', 'Na2PtH6', 'BeWRu2', 'Li2PdHg', 'Ti2MoPt', 'Y2ZnAl', 'Ti2TcIr', 'LiCu2Si', 'ZrNi2In', 'Sc2AgIn', 'LiMgTl2', 'Rb2NiF6', 'Ti2MoIr', 'NiH', 'YAu2In', 'LiMg2Rh', 'Au', 'BeOs2Si', 'Cs2PtCl6', 'ScCu2Ga', 'TlBr', 'KTl2Bi', 'MgZn2Y', 'MgTiIr2', 'ScNbRu2', 'HfRh2Ga', 'TiAu2Zn', 'Ni2AlHf', 'Mg2Pb', 'ZrCu2Zn', 'Na2KSb', 'TiRh2Zn', 'Ti2TcNi', 'MgHfRh2', 'Be2RhNi', 'Y2ZnIn', 'LiPdAl2', 'ScRh2In', 'Be2CoNi', 'Li2O', 'LiNiZn2', 'LiMg2Hg', 'LiNi2Ga', 'CaO', 'Ru2HfAl', 'SnTe', 'LiWRu2', 'ScSe', 'Na2S', 'Cs2PtF6', 'Ti2TcOs', 'Be2RuPt', 'LiScAu2', 'Mg2AuAg', 'Sc2PtNi', 'Ni2AlTi', 'CaF2', 'Rh2TiGa', 'LiRh2Al', 'LiPtIn2', 'ScS', 'YPd2Sn', 'LiPd2Hg', 'Pd2HfIn', 'LiMg2Pt', 'LiAu2Zn', 'BaS', 'Li2NaSb', 'Hf2ReCo', 'Th2BiTe', 'AlCu2Sc', 'ScNi2Sn', 'Ta2WOs', 'Mg3Nd', 'PtGa2', 'HfCu2Zn', 'LiCu2Ge', 'Be2RhPt', 'ReMn2Al', 'LiPtGa2', 'Sc2RuGa', 'LiSc2Rh', 'NbOs2Al', 'BeTiIr2', 'RhAuZn2', 'Sc2OsCu', 'LiPd2Zn', 'YSb', 'TiOs2Si', 'ScBi', 'LiNbRh2', 'Rb2PdBr6', 'Sc2IrCu', 'MgRh2Sn', 'LiBePt2', 'MgAg2Al', 'Ag2MgCd', 'Rh2CdTl', 'Ca2PdAu', 'V2ReOs', 'Ca2MgTl', 'MgAg2Ga', 'MgSc2Al', 'Ba2AuSb', 'NiSi2', 'PdAuCu2', 'Rb2PbCl6', 'Sc2CuGa', 'Cs2PtH6', 'BeIr2Al', 'Kr', 'MgHfIr2', 'PtSn2', 'RuCoAl2', 'AlCu2Hf', 'Cs2TeI6', 'YAu2Cd', 'MgZrPd2', 'BeCo2Si', 'LiHfPt2', 'Li2Se', 'AgCl', 'ScB12', 'BeTiRh2', 'Rb2PdCl6', 'Y2RuPd', 'V2CrRe', 'ScHfRu2', 'MgY2Al', 'LiPdHg2', 'Ru2AlTa', 'Co2ScAl', 'BeCo2Ge', 'LaAs', 'Y2RuZn', 'TaRh2Zn', 'LiCa2Al', 'MgSc2Cd', 'ScRh2Cd', 'Ru2VAl', 'LiIrZn2', 'Ag2MgZn', 'LiPdIn2', 'YN', 'V3Os', 'Be2TiIr', 'TiVTc2', 'CuPt7', 'Be2IrPd', 'MgRh2Ga', 'TiReTc2', 'ScAu2In', 'ScPd2Ga', 'Be2CoPt', 'BaF2', 'Ti2TcRu', 'ScRh2Zn', 'LiPt2In', 'Sc2PtCu', 'CsF', 'ScHfRh2', 'AlNi2Zr', 'NbTc2Si', 'K2PtCl6', 'ZrCu2Cd', 'Pd2TiGa', 'LiZr2Tc', 'ZrPd2Cd', 'LiNi2Sn', 'Cs2ZrCl6', 'Na2TlBi', 'LiMg2Zn', 'ScN', 'KF', 'PbS', 'TiRu2Ga', 'ScCu2In', 'Pb', 'Sc2AgTl', 'Mg2PtAg', 'Sc2AgHg', 'MgPd2Al', 'LiCu2Ga', 'BeNi2Si', 'HfN', 'LiRhAl2', 'TaFe2Ga', 'Cs2SnBr6', 'Sc2IrPd', 'TiTc2Sb', 'CdF2', 'TaOs2Al', 'Rh2SnCu', 'MgRh2Si', 'Pd2AgCd', 'Na2Se', 'Be2RhCu', 'LiMg2Ag', 'MgO', 'Mg2RhAu', 'TbAs', 'LaS', 'MgScRh2', 'ZrRh2Sn', 'TiTaRu2', 'MgTaIr2', 'Ne', 'Ir2ZnAl', 'Zr2OsCu', 'K2Se', 'IK1', 'Rh2TiAl', 'Pd2AgHg', 'Sc2ZnAl', 'LiPd2Si', 'PbTe', 'K2O', 'TiWRe2', 'Be2PtPd', 'Sc2OsPd', 'Li3Bi', 'MgTaRu2', 'HfNbTc2', 'LiNi2Si', 'NaI', 'LiHfRh2', 'Ca2MgIn', 'LiPtZn2', 'Ti2OsRu', 'Hf2ReZn', 'ScNbTc2', 'MgTaRh2', 'TiNbRe2', 'Be2IrCu', 'Pd2AuIn', 'LiNi2Al', 'LiPdCd2', 'Rb2S', 'LiPd2Sb', 'NaPd2Hg', 'UC1', 'Sc2AuZn', 'HfC', 'Mg2Si', 'LiSc2Tc', 'BaCl2', 'LiPd2Cd', 'LiH', 'Ti2MoAl', 'VTc2Si', 'Y2IrPd', 'Sc2IrZn', 'Sc2RuPt', 'HfNi2Zn', 'SrF2', 'Cs2Se', 'Ru2AlGe', 'K2PtH6', 'Na2TlSb', 'Li2PdTl', 'AgF', 'Sc2OsNi', 'Hf2TcRh', 'PtIn2', 'Be2IrPt', 'DyH2', 'LiPd2As', 'BeVOs2', 'Sc2OsGa', 'Ta2NbRu', 'ScNbOs2', 'ScP', 'ScAg2Cd', 'TlI', 'Sc2OsZn', 'SnSb', 'Cs2PtI6', 'Pd2TiSn', 'Ti2TcPt', 'Ti2Rh6B', 'Mg2FeH6', 'Pd2HfAl', 'Au2CuAl', 'K2NiF6', 'YBa2NbO6', 'MgRh2Tl', 'KCl', 'MgIr2Ga', 'Rb2Se', 'Ti2ReZn', 'LiZr2Os', 'NaBr', 'ScIr2In', 'CsBr', 'OsIrAl2', 'Ta2NbOs', 'SrO', 'Li2S', 'ScNi2Ga', 'LiY2Al', 'CsCl', 'ScIr2Ga', 'LiVIr2', 'YHg2Cd', 'MgZrRh2', 'V3Ru', 'SrS', 'Rb2PdF6', 'ScAg2Al', 'LiHfIr2', 'MgS', '(Tl)2PtCl6', 'Sc2RuRh', 'PtAl2', 'TaRu2Zn', 'BeRh2Al', 'Li2PdCd', 'YAu2Mg', 'Mg2PtPd', 'Ru2TiSn', 'Y2RuCu', 'PbSe', 'TiOs2Al', 'Hf2ReIr', 'PaC', 'Cs2HfI6', 'PbF2', 'ScHfOs2', 'Pd2TiAl', 'LiPtAl2', 'MgYCd2', 'Sc2RuAg', 'Ir', 'Al2Cu', 'Ru2VGa', 'SmS', 'SrCl2', 'Ti2AlRe', 'ZrN', 'LiPdZn2', 'MgRh2Ge', 'LiPd2Cu', 'LiPt7', 'ScPd2Al', 'VTc2Ge', 'RhPdZn2', 'LiCu2Al', 'LiZrIr2', 'MgTaOs2', 'IrSn2', 'Rb2ZrCl6', 'Sc2OsAg', 'MgYHg2', 'RhPtCd2', 'ScSb', 'Cs2TiCl6', 'LiZrAu2', 'TiCu2In', 'RuPtAl2', 'BaSe', 'KBr', 'YAg2Mg', 'Sc2RuIr', 'ScRu2Sb', 'MgHfPd2', 'TiPd2Zn', 'VTc2Ga', 'LiPdGa2', 'HfCu2In', 'Fe2Ta(Al)', 'Sc2PtZn', 'Rh', 'Sc2OsAl', 'Be2C', 'Sc2RuPd', 'Ni2TiGa', 'Mg2OsH6', 'AuAl2', 'TiN', 'NaPtCd2', 'TiC', 'ScAg2In', 'CaTe', 'Ti2ReNi', 'Pd2CuZn', 'CaTiF6', 'MgNi2Ga', 'CeO2', 'Rb2PtH6', 'ScPd2Sn', 'MgSc2Tl', 'NaTl2Bi', 'VRu2Zn', 'ScPt2In', 'Fe2VGa', 'LiHfPd2', 'Sc2TcAl', 'ScAu2Al', 'LiPd2In', 'Rh2CuGe', 'Ru2TiAl', 'K2S', 'ZrAu2Al', 'NbRu2In', 'YbTe', 'ScCu2Zn', 'LiPtCd2', 'Sc2OsPt', 'MgNi2In', 'AuAgZn2', 'Ti2RePd', 'Li3Hg', 'Ar', 'Fe2VAl', 'Cu2TiZn', 'Be2RhPd', 'K2PtBr6', 'LiAg2Ge', 'ScRu2Sn', 'SrSe', 'ScPt2Zn', 'Mg2RhPt', 'LiAu2Al', 'Ti2MoNi', 'ErH2', 'RuPdAl2', 'LiNi2Ge', 'AlNi2Sc', 'Sc2RuNi', 'Li3Au', 'RbBr', 'RhPdCd2', 'Cs2GeCl6', 'Pd2ZrAl', 'NaF', 'ThN', 'CdO', 'Li2CdSn', 'LiAlAg2', 'Cs2PbCl6', 'HfIr2Zn', 'ErAs', 'BeTiCo2', 'TiNi2Zn', 'Hf2TcRu', 'LiF', 'HfRu2Ga', 'NaPd2Tl', 'VOs2Al', 'Ru2HfSn', 'LiCo2Si', 'NbRu2Al', 'Mg2RuH6', 'Al', 'CaMgTl2', 'ScRh2Ga', 'CsI', 'LiScTl2', 'ScNi2In', 'Sr2AuSb', 'NaH', 'RuIrAl2', 'NbH2', 'HfAu2Zn', 'MgPd2In', 'K2TiCl6', 'HfRu2Si', 'Fe2NbAl', 'LiHf2Os', 'Hf2MoRh', 'Sc2PtPd', 'ScRh2Tl', 'AlCu2Ti', 'LiPd2Ge', 'LiPd2Al', 'Mg2Sn', 'Ti2TcAl', 'LiRhZn2', 'ZrCu2In', 'BaTe', 'YMg3', 'BaO', 'Cs2SnI6', 'CoSi2', 'VH2', 'LiPt2Al', 'Ti2TcPd', 'Mg2Ge', 'LiTiIr2', 'Y2IrRh', 'NaCl', 'ScHg2Cd', 'LiSc2Ru', 'LiPd2Pb', 'Fe2TiSn']
The length of training, testing, and holdout dataset is:
 images, 414 89 89 
 text, 414 89 89 respectively
Training fold 1...
0.0007
Model: "my_text_model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              
 el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         
                                tentions(last_hidde                                               
                                n_state=(None, 11,                                                
                                768),                                                             
                                 pooler_output=(Non                                               
                                e, 768),                                                          
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 average_pooling1d (AveragePool  (None, 1, 768)      0           ['tf_roberta_model[0][0]']       
 ing1D)                                                                                           
                                                                                                  
 flatten (Flatten)              (None, 768)          0           ['average_pooling1d[0][0]']      
                                                                                                  
 dense_1_text (Dense)           (None, 512)          393728      ['flatten[0][0]']                
                                                                                                  
 bn_1_text (BatchNormalization)  (None, 512)         2048        ['dense_1_text[0][0]']           
                                                                                                  
 dropout_1_text (Dropout)       (None, 512)          0           ['bn_1_text[0][0]']              
                                                                                                  
 dense_2_text (Dense)           (None, 512)          262656      ['dropout_1_text[0][0]']         
                                                                                                  
 bn_2_text (BatchNormalization)  (None, 512)         2048        ['dense_2_text[0][0]']           
                                                                                                  
 dropout_2_text (Dropout)       (None, 512)          0           ['bn_2_text[0][0]']              
                                                                                                  
 dense_3_text (Dense)           (None, 256)          131328      ['dropout_2_text[0][0]']         
                                                                                                  
 bn_3_text (BatchNormalization)  (None, 256)         1024        ['dense_3_text[0][0]']           
                                                                                                  
 dropout_3_text (Dropout)       (None, 256)          0           ['bn_3_text[0][0]']              
                                                                                                  
 input_3 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 dense_4_text (Dense)           (None, 1)            257         ['dropout_3_text[0][0]']         
                                                                                                  
==================================================================================================
Total params: 125,438,721
Trainable params: 790,529
Non-trainable params: 124,648,192
__________________________________________________________________________________________________
None

Search: Running Trial #1

Value             |Best Value So Far |Hyperparameter
0.0007            |0.0007            |learning_rate

0.0007
Model: "my_text_model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              
 el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         
                                tentions(last_hidde                                               
                                n_state=(None, 11,                                                
                                768),                                                             
                                 pooler_output=(Non                                               
                                e, 768),                                                          
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 average_pooling1d (AveragePool  (None, 1, 768)      0           ['tf_roberta_model[1][0]']       
 ing1D)                                                                                           
                                                                                                  
 flatten (Flatten)              (None, 768)          0           ['average_pooling1d[0][0]']      
                                                                                                  
 dense_1_text (Dense)           (None, 512)          393728      ['flatten[0][0]']                
                                                                                                  
 bn_1_text (BatchNormalization)  (None, 512)         2048        ['dense_1_text[0][0]']           
                                                                                                  
 dropout_1_text (Dropout)       (None, 512)          0           ['bn_1_text[0][0]']              
                                                                                                  
 dense_2_text (Dense)           (None, 512)          262656      ['dropout_1_text[0][0]']         
                                                                                                  
 bn_2_text (BatchNormalization)  (None, 512)         2048        ['dense_2_text[0][0]']           
                                                                                                  
 dropout_2_text (Dropout)       (None, 512)          0           ['bn_2_text[0][0]']              
                                                                                                  
 dense_3_text (Dense)           (None, 256)          131328      ['dropout_2_text[0][0]']         
                                                                                                  
 bn_3_text (BatchNormalization)  (None, 256)         1024        ['dense_3_text[0][0]']           
                                                                                                  
 dropout_3_text (Dropout)       (None, 256)          0           ['bn_3_text[0][0]']              
                                                                                                  
 input_1 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 dense_4_text (Dense)           (None, 1)            257         ['dropout_3_text[0][0]']         
                                                                                                  
==================================================================================================
Total params: 125,438,721
Trainable params: 790,529
Non-trainable params: 124,648,192
__________________________________________________________________________________________________
None
 1/11 [=>............................] - ETA: 1:18 - loss: 2.2098 4/11 [=========>....................] - ETA: 0s - loss: 2.4588   7/11 [==================>...........] - ETA: 0s - loss: 2.140110/11 [==========================>...] - ETA: 0s - loss: 1.991111/11 [==============================] - 17s 901ms/step - loss: 1.9824 - val_loss: 3.6419
[2K[2KTrial 1 Complete [00h 00m 19s]
val_loss: 3.641857385635376

Best val_loss So Far: 3.641857385635376
Total elapsed time: 00h 00m 19s
Best Learning Rate for fold 1 : 0.0007
0.0007
Model: "my_text_model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              
 el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         
                                tentions(last_hidde                                               
                                n_state=(None, 11,                                                
                                768),                                                             
                                 pooler_output=(Non                                               
                                e, 768),                                                          
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 average_pooling1d_1 (AveragePo  (None, 1, 768)      0           ['tf_roberta_model[2][0]']       
 oling1D)                                                                                         
                                                                                                  
 flatten_1 (Flatten)            (None, 768)          0           ['average_pooling1d_1[0][0]']    
                                                                                                  
 dense_1_text (Dense)           (None, 512)          393728      ['flatten_1[0][0]']              
                                                                                                  
 bn_1_text (BatchNormalization)  (None, 512)         2048        ['dense_1_text[0][0]']           
                                                                                                  
 dropout_1_text (Dropout)       (None, 512)          0           ['bn_1_text[0][0]']              
                                                                                                  
 dense_2_text (Dense)           (None, 512)          262656      ['dropout_1_text[0][0]']         
                                                                                                  
 bn_2_text (BatchNormalization)  (None, 512)         2048        ['dense_2_text[0][0]']           
                                                                                                  
 dropout_2_text (Dropout)       (None, 512)          0           ['bn_2_text[0][0]']              
                                                                                                  
 dense_3_text (Dense)           (None, 256)          131328      ['dropout_2_text[0][0]']         
                                                                                                  
 bn_3_text (BatchNormalization)  (None, 256)         1024        ['dense_3_text[0][0]']           
                                                                                                  
 dropout_3_text (Dropout)       (None, 256)          0           ['bn_3_text[0][0]']              
                                                                                                  
 input_2 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 dense_4_text (Dense)           (None, 1)            257         ['dropout_3_text[0][0]']         
                                                                                                  
==================================================================================================
Total params: 125,438,721
Trainable params: 790,529
Non-trainable params: 124,648,192
__________________________________________________________________________________________________
None
Model: "my_text_model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              
 el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         
                                tentions(last_hidde                                               
                                n_state=(None, 11,                                                
                                768),                                                             
                                 pooler_output=(Non                                               
                                e, 768),                                                          
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 average_pooling1d_1 (AveragePo  (None, 1, 768)      0           ['tf_roberta_model[2][0]']       
 oling1D)                                                                                         
                                                                                                  
 flatten_1 (Flatten)            (None, 768)          0           ['average_pooling1d_1[0][0]']    
                                                                                                  
 dense_1_text (Dense)           (None, 512)          393728      ['flatten_1[0][0]']              
                                                                                                  
 bn_1_text (BatchNormalization)  (None, 512)         2048        ['dense_1_text[0][0]']           
                                                                                                  
 dropout_1_text (Dropout)       (None, 512)          0           ['bn_1_text[0][0]']              
                                                                                                  
 dense_2_text (Dense)           (None, 512)          262656      ['dropout_1_text[0][0]']         
                                                                                                  
 bn_2_text (BatchNormalization)  (None, 512)         2048        ['dense_2_text[0][0]']           
                                                                                                  
 dropout_2_text (Dropout)       (None, 512)          0           ['bn_2_text[0][0]']              
                                                                                                  
 dense_3_text (Dense)           (None, 256)          131328      ['dropout_2_text[0][0]']         
                                                                                                  
 bn_3_text (BatchNormalization)  (None, 256)         1024        ['dense_3_text[0][0]']           
                                                                                                  
 dropout_3_text (Dropout)       (None, 256)          0           ['bn_3_text[0][0]']              
                                                                                                  
 input_2 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 dense_4_text (Dense)           (None, 1)            257         ['dropout_3_text[0][0]']         
                                                                                                  
==================================================================================================
Total params: 125,438,721
Trainable params: 790,529
Non-trainable params: 124,648,192
__________________________________________________________________________________________________
FINAL MODEL: None
Epoch 1/700
 1/11 [=>............................] - ETA: 1:17 - loss: 2.6951 4/11 [=========>....................] - ETA: 0s - loss: 2.9522   7/11 [==================>...........] - ETA: 0s - loss: 2.652510/11 [==========================>...] - ETA: 0s - loss: 2.4618
Epoch 1: val_loss improved from inf to 3.63534, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 16s 793ms/step - loss: 2.4209 - val_loss: 3.6353
Epoch 2/700
 1/11 [=>............................] - ETA: 0s - loss: 1.1426 4/11 [=========>....................] - ETA: 0s - loss: 1.1215 7/11 [==================>...........] - ETA: 0s - loss: 1.098010/11 [==========================>...] - ETA: 0s - loss: 1.1418
Epoch 2: val_loss did not improve from 3.63534
11/11 [==============================] - 0s 28ms/step - loss: 1.1346 - val_loss: 3.6361
Epoch 3/700
 1/11 [=>............................] - ETA: 0s - loss: 1.0152 4/11 [=========>....................] - ETA: 0s - loss: 1.0045 7/11 [==================>...........] - ETA: 0s - loss: 1.082110/11 [==========================>...] - ETA: 0s - loss: 1.0223
Epoch 3: val_loss improved from 3.63534 to 3.62735, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 6s 577ms/step - loss: 1.0058 - val_loss: 3.6274
Epoch 4/700
 1/11 [=>............................] - ETA: 0s - loss: 0.9452 4/11 [=========>....................] - ETA: 0s - loss: 0.9335 7/11 [==================>...........] - ETA: 0s - loss: 0.837110/11 [==========================>...] - ETA: 0s - loss: 0.7920
Epoch 4: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 28ms/step - loss: 0.7886 - val_loss: 3.7022
Epoch 5/700
 1/11 [=>............................] - ETA: 0s - loss: 1.1691 4/11 [=========>....................] - ETA: 0s - loss: 0.8196 7/11 [==================>...........] - ETA: 0s - loss: 0.744810/11 [==========================>...] - ETA: 0s - loss: 0.6660
Epoch 5: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 27ms/step - loss: 0.6696 - val_loss: 3.6973
Epoch 6/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4647 4/11 [=========>....................] - ETA: 0s - loss: 0.5212 7/11 [==================>...........] - ETA: 0s - loss: 0.594110/11 [==========================>...] - ETA: 0s - loss: 0.5738
Epoch 6: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 29ms/step - loss: 0.5733 - val_loss: 3.6822
Epoch 7/700
 1/11 [=>............................] - ETA: 0s - loss: 0.6182 4/11 [=========>....................] - ETA: 0s - loss: 0.5179 7/11 [==================>...........] - ETA: 0s - loss: 0.502110/11 [==========================>...] - ETA: 0s - loss: 0.4854
Epoch 7: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 28ms/step - loss: 0.4873 - val_loss: 3.7549
Epoch 8/700
 1/11 [=>............................] - ETA: 0s - loss: 0.5260 4/11 [=========>....................] - ETA: 0s - loss: 0.3419 7/11 [==================>...........] - ETA: 0s - loss: 0.351310/11 [==========================>...] - ETA: 0s - loss: 0.3896
Epoch 8: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 28ms/step - loss: 0.4124 - val_loss: 3.7263
Epoch 9/700
 1/11 [=>............................] - ETA: 0s - loss: 0.6043 4/11 [=========>....................] - ETA: 0s - loss: 0.5680 7/11 [==================>...........] - ETA: 0s - loss: 0.609010/11 [==========================>...] - ETA: 0s - loss: 0.5971
Epoch 9: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 28ms/step - loss: 0.6065 - val_loss: 3.7962
Epoch 10/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2707 4/11 [=========>....................] - ETA: 0s - loss: 0.2902 7/11 [==================>...........] - ETA: 0s - loss: 0.416910/11 [==========================>...] - ETA: 0s - loss: 0.4372
Epoch 10: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 27ms/step - loss: 0.4341 - val_loss: 3.7399
Epoch 11/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4606 4/11 [=========>....................] - ETA: 0s - loss: 0.4822 7/11 [==================>...........] - ETA: 0s - loss: 0.423110/11 [==========================>...] - ETA: 0s - loss: 0.4160
Epoch 11: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 28ms/step - loss: 0.4366 - val_loss: 3.7617
Epoch 12/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4191 4/11 [=========>....................] - ETA: 0s - loss: 0.3343 7/11 [==================>...........] - ETA: 0s - loss: 0.403610/11 [==========================>...] - ETA: 0s - loss: 0.3989
Epoch 12: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 27ms/step - loss: 0.3986 - val_loss: 3.7116
Epoch 13/700
 1/11 [=>............................] - ETA: 0s - loss: 0.6295 4/11 [=========>....................] - ETA: 0s - loss: 0.3645 7/11 [==================>...........] - ETA: 0s - loss: 0.373210/11 [==========================>...] - ETA: 0s - loss: 0.3723
Epoch 13: val_loss did not improve from 3.62735
11/11 [==============================] - 0s 27ms/step - loss: 0.3747 - val_loss: 3.6910
Epoch 14/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4004 4/11 [=========>....................] - ETA: 0s - loss: 0.3713 7/11 [==================>...........] - ETA: 0s - loss: 0.419910/11 [==========================>...] - ETA: 0s - loss: 0.4220
Epoch 14: val_loss improved from 3.62735 to 3.61013, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 6s 578ms/step - loss: 0.4141 - val_loss: 3.6101
Epoch 15/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3345 4/11 [=========>....................] - ETA: 0s - loss: 0.3857 7/11 [==================>...........] - ETA: 0s - loss: 0.411410/11 [==========================>...] - ETA: 0s - loss: 0.3709
Epoch 15: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.3729 - val_loss: 3.8006
Epoch 16/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4049 4/11 [=========>....................] - ETA: 0s - loss: 0.4378 7/11 [==================>...........] - ETA: 0s - loss: 0.410310/11 [==========================>...] - ETA: 0s - loss: 0.3986
Epoch 16: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.3922 - val_loss: 3.7198
Epoch 17/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2575 4/11 [=========>....................] - ETA: 0s - loss: 0.2728 7/11 [==================>...........] - ETA: 0s - loss: 0.319110/11 [==========================>...] - ETA: 0s - loss: 0.3217
Epoch 17: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.3197 - val_loss: 3.7340
Epoch 18/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3812 4/11 [=========>....................] - ETA: 0s - loss: 0.3561 7/11 [==================>...........] - ETA: 0s - loss: 0.322410/11 [==========================>...] - ETA: 0s - loss: 0.3276
Epoch 18: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.3241 - val_loss: 3.6557
Epoch 19/700
 1/11 [=>............................] - ETA: 0s - loss: 0.5214 4/11 [=========>....................] - ETA: 0s - loss: 0.3703 7/11 [==================>...........] - ETA: 0s - loss: 0.308410/11 [==========================>...] - ETA: 0s - loss: 0.2939
Epoch 19: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.2952 - val_loss: 3.6508
Epoch 20/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3403 4/11 [=========>....................] - ETA: 0s - loss: 0.3146 7/11 [==================>...........] - ETA: 0s - loss: 0.291910/11 [==========================>...] - ETA: 0s - loss: 0.2766
Epoch 20: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.2730 - val_loss: 3.6702
Epoch 21/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2495 4/11 [=========>....................] - ETA: 0s - loss: 0.2388 7/11 [==================>...........] - ETA: 0s - loss: 0.260310/11 [==========================>...] - ETA: 0s - loss: 0.2456
Epoch 21: val_loss did not improve from 3.61013
11/11 [==============================] - 0s 27ms/step - loss: 0.2477 - val_loss: 3.6256
Epoch 22/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2976 4/11 [=========>....................] - ETA: 0s - loss: 0.2368 7/11 [==================>...........] - ETA: 0s - loss: 0.209810/11 [==========================>...] - ETA: 0s - loss: 0.2354
Epoch 22: val_loss improved from 3.61013 to 3.59042, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 6s 580ms/step - loss: 0.2446 - val_loss: 3.5904
Epoch 23/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3629 4/11 [=========>....................] - ETA: 0s - loss: 0.3088 7/11 [==================>...........] - ETA: 0s - loss: 0.289710/11 [==========================>...] - ETA: 0s - loss: 0.3237
Epoch 23: val_loss did not improve from 3.59042
11/11 [==============================] - 0s 28ms/step - loss: 0.3199 - val_loss: 3.7386
Epoch 24/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3141 4/11 [=========>....................] - ETA: 0s - loss: 0.3033 7/11 [==================>...........] - ETA: 0s - loss: 0.339310/11 [==========================>...] - ETA: 0s - loss: 0.3164
Epoch 24: val_loss improved from 3.59042 to 3.58996, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 6s 574ms/step - loss: 0.3196 - val_loss: 3.5900
Epoch 25/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3741 4/11 [=========>....................] - ETA: 0s - loss: 0.3095 7/11 [==================>...........] - ETA: 0s - loss: 0.277010/11 [==========================>...] - ETA: 0s - loss: 0.2503
Epoch 25: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2496 - val_loss: 3.6125
Epoch 26/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2762 4/11 [=========>....................] - ETA: 0s - loss: 0.2377 7/11 [==================>...........] - ETA: 0s - loss: 0.214310/11 [==========================>...] - ETA: 0s - loss: 0.2555
Epoch 26: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2577 - val_loss: 3.6929
Epoch 27/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2469 4/11 [=========>....................] - ETA: 0s - loss: 0.2354 7/11 [==================>...........] - ETA: 0s - loss: 0.247810/11 [==========================>...] - ETA: 0s - loss: 0.2751
Epoch 27: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2693 - val_loss: 3.6996
Epoch 28/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1846 4/11 [=========>....................] - ETA: 0s - loss: 0.2959 7/11 [==================>...........] - ETA: 0s - loss: 0.311710/11 [==========================>...] - ETA: 0s - loss: 0.2956
Epoch 28: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2976 - val_loss: 3.6129
Epoch 29/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2254 4/11 [=========>....................] - ETA: 0s - loss: 0.3124 7/11 [==================>...........] - ETA: 0s - loss: 0.275110/11 [==========================>...] - ETA: 0s - loss: 0.2613
Epoch 29: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2661 - val_loss: 3.6694
Epoch 30/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4039 4/11 [=========>....................] - ETA: 0s - loss: 0.3201 7/11 [==================>...........] - ETA: 0s - loss: 0.298710/11 [==========================>...] - ETA: 0s - loss: 0.3071
Epoch 30: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.3080 - val_loss: 3.7670
Epoch 31/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1883 4/11 [=========>....................] - ETA: 0s - loss: 0.2360 7/11 [==================>...........] - ETA: 0s - loss: 0.266610/11 [==========================>...] - ETA: 0s - loss: 0.2349
Epoch 31: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 29ms/step - loss: 0.2347 - val_loss: 3.6898
Epoch 32/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1791 4/11 [=========>....................] - ETA: 0s - loss: 0.2227 7/11 [==================>...........] - ETA: 0s - loss: 0.202610/11 [==========================>...] - ETA: 0s - loss: 0.1860
Epoch 32: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 28ms/step - loss: 0.1985 - val_loss: 3.6857
Epoch 33/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2973 4/11 [=========>....................] - ETA: 0s - loss: 0.2437 7/11 [==================>...........] - ETA: 0s - loss: 0.233610/11 [==========================>...] - ETA: 0s - loss: 0.2298
Epoch 33: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 29ms/step - loss: 0.2336 - val_loss: 3.6463
Epoch 34/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2783 4/11 [=========>....................] - ETA: 0s - loss: 0.3503 7/11 [==================>...........] - ETA: 0s - loss: 0.314510/11 [==========================>...] - ETA: 0s - loss: 0.2938
Epoch 34: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 28ms/step - loss: 0.2948 - val_loss: 3.6749
Epoch 35/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2354 4/11 [=========>....................] - ETA: 0s - loss: 0.2012 7/11 [==================>...........] - ETA: 0s - loss: 0.175410/11 [==========================>...] - ETA: 0s - loss: 0.2237
Epoch 35: val_loss did not improve from 3.58996
11/11 [==============================] - 0s 27ms/step - loss: 0.2311 - val_loss: 3.6486
Epoch 36/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1435 4/11 [=========>....................] - ETA: 0s - loss: 0.1902 7/11 [==================>...........] - ETA: 0s - loss: 0.230310/11 [==========================>...] - ETA: 0s - loss: 0.2226
Epoch 36: val_loss improved from 3.58996 to 3.58881, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 7s 672ms/step - loss: 0.2215 - val_loss: 3.5888
Epoch 37/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1465 4/11 [=========>....................] - ETA: 0s - loss: 0.2656 7/11 [==================>...........] - ETA: 0s - loss: 0.221110/11 [==========================>...] - ETA: 0s - loss: 0.2053
Epoch 37: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.2017 - val_loss: 3.6572
Epoch 38/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1397 4/11 [=========>....................] - ETA: 0s - loss: 0.2183 7/11 [==================>...........] - ETA: 0s - loss: 0.182310/11 [==========================>...] - ETA: 0s - loss: 0.1651
Epoch 38: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.1662 - val_loss: 3.6476
Epoch 39/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2199 4/11 [=========>....................] - ETA: 0s - loss: 0.2351 7/11 [==================>...........] - ETA: 0s - loss: 0.234510/11 [==========================>...] - ETA: 0s - loss: 0.2086
Epoch 39: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.2093 - val_loss: 3.6272
Epoch 40/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2384 4/11 [=========>....................] - ETA: 0s - loss: 0.2137 7/11 [==================>...........] - ETA: 0s - loss: 0.217310/11 [==========================>...] - ETA: 0s - loss: 0.2245
Epoch 40: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 29ms/step - loss: 0.2336 - val_loss: 3.6226
Epoch 41/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3310 4/11 [=========>....................] - ETA: 0s - loss: 0.1968 7/11 [==================>...........] - ETA: 0s - loss: 0.182810/11 [==========================>...] - ETA: 0s - loss: 0.1859
Epoch 41: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 29ms/step - loss: 0.1941 - val_loss: 3.6785
Epoch 42/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1631 4/11 [=========>....................] - ETA: 0s - loss: 0.1584 7/11 [==================>...........] - ETA: 0s - loss: 0.168310/11 [==========================>...] - ETA: 0s - loss: 0.1865
Epoch 42: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.1826 - val_loss: 3.6345
Epoch 43/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1507 4/11 [=========>....................] - ETA: 0s - loss: 0.1922 7/11 [==================>...........] - ETA: 0s - loss: 0.185910/11 [==========================>...] - ETA: 0s - loss: 0.1916
Epoch 43: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.1935 - val_loss: 3.6950
Epoch 44/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3274 4/11 [=========>....................] - ETA: 0s - loss: 0.2700 7/11 [==================>...........] - ETA: 0s - loss: 0.235110/11 [==========================>...] - ETA: 0s - loss: 0.2168
Epoch 44: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.2158 - val_loss: 3.6704
Epoch 45/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1234 4/11 [=========>....................] - ETA: 0s - loss: 0.1606 7/11 [==================>...........] - ETA: 0s - loss: 0.171310/11 [==========================>...] - ETA: 0s - loss: 0.1799
Epoch 45: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.1765 - val_loss: 3.6495
Epoch 46/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1204 4/11 [=========>....................] - ETA: 0s - loss: 0.1211 7/11 [==================>...........] - ETA: 0s - loss: 0.155010/11 [==========================>...] - ETA: 0s - loss: 0.1554
Epoch 46: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 28ms/step - loss: 0.1568 - val_loss: 3.6506
Epoch 47/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2539 4/11 [=========>....................] - ETA: 0s - loss: 0.1989 7/11 [==================>...........] - ETA: 0s - loss: 0.207010/11 [==========================>...] - ETA: 0s - loss: 0.2008
Epoch 47: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 27ms/step - loss: 0.1979 - val_loss: 3.6327
Epoch 48/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1013 4/11 [=========>....................] - ETA: 0s - loss: 0.1318 7/11 [==================>...........] - ETA: 0s - loss: 0.162610/11 [==========================>...] - ETA: 0s - loss: 0.1567
Epoch 48: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 27ms/step - loss: 0.1765 - val_loss: 3.6469
Epoch 49/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1086 4/11 [=========>....................] - ETA: 0s - loss: 0.1672 7/11 [==================>...........] - ETA: 0s - loss: 0.174710/11 [==========================>...] - ETA: 0s - loss: 0.1685
Epoch 49: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 27ms/step - loss: 0.1690 - val_loss: 3.6300
Epoch 50/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1356 4/11 [=========>....................] - ETA: 0s - loss: 0.1620 7/11 [==================>...........] - ETA: 0s - loss: 0.191010/11 [==========================>...] - ETA: 0s - loss: 0.1946
Epoch 50: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 27ms/step - loss: 0.1921 - val_loss: 3.6332
Epoch 51/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1306 4/11 [=========>....................] - ETA: 0s - loss: 0.1440 7/11 [==================>...........] - ETA: 0s - loss: 0.133610/11 [==========================>...] - ETA: 0s - loss: 0.1511
Epoch 51: val_loss did not improve from 3.58881
11/11 [==============================] - 0s 42ms/step - loss: 0.1537 - val_loss: 3.6283
1/3 [=========>....................] - ETA: 3s - loss: 0.06403/3 [==============================] - 2s 16ms/step - loss: 3.0688
Fold 1 Loss: 3.068756341934204
Average Loss: 3.068756341934204

PERFORMANCES of the pretrained model, no fine-tuning

1/3 [=========>....................] - ETA: 0s - loss: 0.09733/3 [==============================] - 0s 16ms/step - loss: 0.0787
1/3 [=========>....................] - ETA: 3s3/3 [==============================] - 2s 17ms/step
Test Loss (MSE): 0.07873556762933731
Mean Squared Error (MSE): 0.07873556
Mean Absolute Error (MAE): 0.22445188
R-squared (R2) Score: -0.5145924207129466
 1/13 [=>............................] - ETA: 0s 5/13 [==========>...................] - ETA: 0s 9/13 [===================>..........] - ETA: 0s13/13 [==============================] - ETA: 0s13/13 [==============================] - 0s 16ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 17ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 16ms/step
Training rmse: 0.88  and Testing rmse: 0.28 and Hold rmse: 1.75
Training R2: 0.01  and Testing R2: -0.51 and Hold R2: -0.07

____________
FINE-TUNING
____________

Epoch 1/700
 1/13 [=>............................] - ETA: 2:11 - loss: 0.2349 3/13 [=====>........................] - ETA: 0s - loss: 0.1804   5/13 [==========>...................] - ETA: 0s - loss: 0.1992 7/13 [===============>..............] - ETA: 0s - loss: 1.5427 9/13 [===================>..........] - ETA: 0s - loss: 1.238911/13 [========================>.....] - ETA: 0s - loss: 1.076513/13 [==============================] - ETA: 0s - loss: 0.9533
Epoch 1: val_loss improved from inf to 0.05364, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 28s 1s/step - loss: 0.9533 - val_loss: 0.0536
Epoch 2/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1769 3/13 [=====>........................] - ETA: 0s - loss: 0.1879 5/13 [==========>...................] - ETA: 0s - loss: 0.1806 7/13 [===============>..............] - ETA: 0s - loss: 0.1759 9/13 [===================>..........] - ETA: 0s - loss: 0.191711/13 [========================>.....] - ETA: 0s - loss: 0.201013/13 [==============================] - ETA: 0s - loss: 0.9148
Epoch 2: val_loss improved from 0.05364 to 0.04698, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 16s 1s/step - loss: 0.9148 - val_loss: 0.0470
Epoch 3/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1126 3/13 [=====>........................] - ETA: 0s - loss: 0.1677 5/13 [==========>...................] - ETA: 0s - loss: 0.1994 7/13 [===============>..............] - ETA: 0s - loss: 0.2353 9/13 [===================>..........] - ETA: 0s - loss: 1.305211/13 [========================>.....] - ETA: 0s - loss: 1.103413/13 [==============================] - ETA: 0s - loss: 0.9732
Epoch 3: val_loss improved from 0.04698 to 0.04582, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 16s 1s/step - loss: 0.9732 - val_loss: 0.0458
Epoch 4/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4302 3/13 [=====>........................] - ETA: 0s - loss: 0.2746 5/13 [==========>...................] - ETA: 0s - loss: 0.2237 7/13 [===============>..............] - ETA: 0s - loss: 1.4880 9/13 [===================>..........] - ETA: 0s - loss: 1.201011/13 [========================>.....] - ETA: 0s - loss: 1.021613/13 [==============================] - ETA: 0s - loss: 0.9187
Epoch 4: val_loss did not improve from 0.04582
13/13 [==============================] - 1s 43ms/step - loss: 0.9187 - val_loss: 0.0602
Epoch 5/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1590 3/13 [=====>........................] - ETA: 0s - loss: 0.1854 5/13 [==========>...................] - ETA: 0s - loss: 0.1701 7/13 [===============>..............] - ETA: 0s - loss: 0.1824 9/13 [===================>..........] - ETA: 0s - loss: 0.219411/13 [========================>.....] - ETA: 0s - loss: 1.149713/13 [==============================] - ETA: 0s - loss: 1.0034
Epoch 5: val_loss did not improve from 0.04582
13/13 [==============================] - 1s 42ms/step - loss: 1.0034 - val_loss: 0.0541
Epoch 6/700
 1/13 [=>............................] - ETA: 0s - loss: 0.0915 3/13 [=====>........................] - ETA: 0s - loss: 0.1718 5/13 [==========>...................] - ETA: 0s - loss: 0.1687 7/13 [===============>..............] - ETA: 0s - loss: 0.1987 9/13 [===================>..........] - ETA: 0s - loss: 0.184511/13 [========================>.....] - ETA: 0s - loss: 0.190713/13 [==============================] - ETA: 0s - loss: 0.9454
Epoch 6: val_loss improved from 0.04582 to 0.04291, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 18s 2s/step - loss: 0.9454 - val_loss: 0.0429
Epoch 7/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1633 3/13 [=====>........................] - ETA: 0s - loss: 0.1914 5/13 [==========>...................] - ETA: 0s - loss: 0.1886 7/13 [===============>..............] - ETA: 0s - loss: 1.5584 9/13 [===================>..........] - ETA: 0s - loss: 1.266711/13 [========================>.....] - ETA: 0s - loss: 1.064213/13 [==============================] - ETA: 0s - loss: 0.9287
Epoch 7: val_loss improved from 0.04291 to 0.03923, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 16s 1s/step - loss: 0.9287 - val_loss: 0.0392
Epoch 8/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1385 3/13 [=====>........................] - ETA: 0s - loss: 0.1745 5/13 [==========>...................] - ETA: 0s - loss: 0.2059 7/13 [===============>..............] - ETA: 0s - loss: 0.1878 9/13 [===================>..........] - ETA: 0s - loss: 0.180511/13 [========================>.....] - ETA: 0s - loss: 0.176513/13 [==============================] - ETA: 0s - loss: 0.8798
Epoch 8: val_loss did not improve from 0.03923
13/13 [==============================] - 1s 44ms/step - loss: 0.8798 - val_loss: 0.0396
Epoch 9/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1899 3/13 [=====>........................] - ETA: 0s - loss: 0.1572 5/13 [==========>...................] - ETA: 0s - loss: 2.0469 7/13 [===============>..............] - ETA: 0s - loss: 1.5553 9/13 [===================>..........] - ETA: 0s - loss: 1.257211/13 [========================>.....] - ETA: 0s - loss: 1.071813/13 [==============================] - ETA: 0s - loss: 0.9366
Epoch 9: val_loss did not improve from 0.03923
13/13 [==============================] - 1s 42ms/step - loss: 0.9366 - val_loss: 0.0407
Epoch 10/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1314 3/13 [=====>........................] - ETA: 0s - loss: 0.1931 5/13 [==========>...................] - ETA: 0s - loss: 1.9292 7/13 [===============>..............] - ETA: 0s - loss: 1.4732 9/13 [===================>..........] - ETA: 0s - loss: 1.179011/13 [========================>.....] - ETA: 0s - loss: 0.991913/13 [==============================] - ETA: 0s - loss: 0.8725
Epoch 10: val_loss improved from 0.03923 to 0.03681, saving model to results/RobertaBase_g_vrh_1_word/text_only/saved_models/finetuned.hdf5
13/13 [==============================] - 16s 1s/step - loss: 0.8725 - val_loss: 0.0368
Epoch 11/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2564 3/13 [=====>........................] - ETA: 0s - loss: 0.2062 5/13 [==========>...................] - ETA: 0s - loss: 0.2193 7/13 [===============>..............] - ETA: 0s - loss: 0.2449 9/13 [===================>..........] - ETA: 0s - loss: 0.235711/13 [========================>.....] - ETA: 0s - loss: 0.215813/13 [==============================] - ETA: 0s - loss: 0.8979
Epoch 11: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8979 - val_loss: 0.0391
Epoch 12/700
 1/13 [=>............................] - ETA: 0s - loss: 9.4097 3/13 [=====>........................] - ETA: 0s - loss: 3.2300 5/13 [==========>...................] - ETA: 0s - loss: 2.0052 7/13 [===============>..............] - ETA: 0s - loss: 1.4899 9/13 [===================>..........] - ETA: 0s - loss: 1.196011/13 [========================>.....] - ETA: 0s - loss: 1.012913/13 [==============================] - ETA: 0s - loss: 0.8922
Epoch 12: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8922 - val_loss: 0.0436
Epoch 13/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2207 3/13 [=====>........................] - ETA: 0s - loss: 0.1804 5/13 [==========>...................] - ETA: 0s - loss: 2.0463 7/13 [===============>..............] - ETA: 0s - loss: 1.5239 9/13 [===================>..........] - ETA: 0s - loss: 1.215911/13 [========================>.....] - ETA: 0s - loss: 1.021313/13 [==============================] - ETA: 0s - loss: 0.8921
Epoch 13: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 42ms/step - loss: 0.8921 - val_loss: 0.0491
Epoch 14/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3472 3/13 [=====>........................] - ETA: 0s - loss: 0.2481 5/13 [==========>...................] - ETA: 0s - loss: 0.2217 7/13 [===============>..............] - ETA: 0s - loss: 0.2468 9/13 [===================>..........] - ETA: 0s - loss: 0.240211/13 [========================>.....] - ETA: 0s - loss: 0.221613/13 [==============================] - ETA: 0s - loss: 0.8232
Epoch 14: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8232 - val_loss: 0.0551
Epoch 15/700
 1/13 [=>............................] - ETA: 0s - loss: 8.7483 3/13 [=====>........................] - ETA: 0s - loss: 3.0767 5/13 [==========>...................] - ETA: 0s - loss: 1.9394 7/13 [===============>..............] - ETA: 0s - loss: 1.4538 9/13 [===================>..........] - ETA: 0s - loss: 1.198011/13 [========================>.....] - ETA: 0s - loss: 1.027013/13 [==============================] - ETA: 0s - loss: 0.9011
Epoch 15: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.9011 - val_loss: 0.0578
Epoch 16/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2895 3/13 [=====>........................] - ETA: 0s - loss: 2.9082 5/13 [==========>...................] - ETA: 0s - loss: 1.8525 7/13 [===============>..............] - ETA: 0s - loss: 1.3801 9/13 [===================>..........] - ETA: 0s - loss: 1.128711/13 [========================>.....] - ETA: 0s - loss: 0.972213/13 [==============================] - ETA: 0s - loss: 0.8532
Epoch 16: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 42ms/step - loss: 0.8532 - val_loss: 0.1052
Epoch 17/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2490 3/13 [=====>........................] - ETA: 0s - loss: 0.2158 5/13 [==========>...................] - ETA: 0s - loss: 1.8070 7/13 [===============>..............] - ETA: 0s - loss: 1.3386 9/13 [===================>..........] - ETA: 0s - loss: 1.081611/13 [========================>.....] - ETA: 0s - loss: 0.940513/13 [==============================] - ETA: 0s - loss: 0.8345
Epoch 17: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8345 - val_loss: 0.0646
Epoch 18/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2749 3/13 [=====>........................] - ETA: 0s - loss: 0.2108 5/13 [==========>...................] - ETA: 0s - loss: 0.2098 7/13 [===============>..............] - ETA: 0s - loss: 0.2184 9/13 [===================>..........] - ETA: 0s - loss: 0.212611/13 [========================>.....] - ETA: 0s - loss: 0.217313/13 [==============================] - ETA: 0s - loss: 0.9259
Epoch 18: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.9259 - val_loss: 0.0444
Epoch 19/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1753 3/13 [=====>........................] - ETA: 0s - loss: 0.2438 5/13 [==========>...................] - ETA: 0s - loss: 0.1994 7/13 [===============>..............] - ETA: 0s - loss: 0.2174 9/13 [===================>..........] - ETA: 0s - loss: 0.199411/13 [========================>.....] - ETA: 0s - loss: 0.210113/13 [==============================] - ETA: 0s - loss: 0.8517
Epoch 19: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 42ms/step - loss: 0.8517 - val_loss: 0.0499
Epoch 20/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1755 3/13 [=====>........................] - ETA: 0s - loss: 0.1832 5/13 [==========>...................] - ETA: 0s - loss: 0.1859 7/13 [===============>..............] - ETA: 0s - loss: 0.1793 9/13 [===================>..........] - ETA: 0s - loss: 1.168011/13 [========================>.....] - ETA: 0s - loss: 0.999813/13 [==============================] - ETA: 0s - loss: 0.8874
Epoch 20: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8874 - val_loss: 0.0573
Epoch 21/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2697 3/13 [=====>........................] - ETA: 0s - loss: 0.2443 5/13 [==========>...................] - ETA: 0s - loss: 0.2525 7/13 [===============>..............] - ETA: 0s - loss: 1.3636 9/13 [===================>..........] - ETA: 0s - loss: 1.111911/13 [========================>.....] - ETA: 0s - loss: 0.944913/13 [==============================] - ETA: 0s - loss: 0.8253
Epoch 21: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8253 - val_loss: 0.0601
Epoch 22/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1560 3/13 [=====>........................] - ETA: 0s - loss: 0.1492 5/13 [==========>...................] - ETA: 0s - loss: 0.1678 7/13 [===============>..............] - ETA: 0s - loss: 0.1686 9/13 [===================>..........] - ETA: 0s - loss: 0.904111/13 [========================>.....] - ETA: 0s - loss: 0.767413/13 [==============================] - ETA: 0s - loss: 0.6912
Epoch 22: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 42ms/step - loss: 0.6912 - val_loss: 0.0672
Epoch 23/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2478 3/13 [=====>........................] - ETA: 0s - loss: 0.2868 5/13 [==========>...................] - ETA: 0s - loss: 0.2718 7/13 [===============>..............] - ETA: 0s - loss: 0.2597 9/13 [===================>..........] - ETA: 0s - loss: 1.088211/13 [========================>.....] - ETA: 0s - loss: 0.923713/13 [==============================] - ETA: 0s - loss: 0.8023
Epoch 23: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 43ms/step - loss: 0.8023 - val_loss: 0.0722
Epoch 24/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1875 3/13 [=====>........................] - ETA: 0s - loss: 0.2639 5/13 [==========>...................] - ETA: 0s - loss: 0.2403 7/13 [===============>..............] - ETA: 0s - loss: 0.2422 9/13 [===================>..........] - ETA: 0s - loss: 0.237911/13 [========================>.....] - ETA: 0s - loss: 0.869213/13 [==============================] - ETA: 0s - loss: 0.7729
Epoch 24: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 42ms/step - loss: 0.7729 - val_loss: 0.0810
Epoch 25/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1601 3/13 [=====>........................] - ETA: 0s - loss: 2.2206 5/13 [==========>...................] - ETA: 0s - loss: 1.4211 7/13 [===============>..............] - ETA: 0s - loss: 1.0624 9/13 [===================>..........] - ETA: 0s - loss: 0.874611/13 [========================>.....] - ETA: 0s - loss: 0.739613/13 [==============================] - ETA: 0s - loss: 0.6607
Epoch 25: val_loss did not improve from 0.03681
13/13 [==============================] - 1s 64ms/step - loss: 0.6607 - val_loss: 0.0993
!!!THE FINAL RESULTS FOR TEXT ONLY:
 1/13 [=>............................] - ETA: 23s 5/13 [==========>...................] - ETA: 0s  9/13 [===================>..........] - ETA: 0s12/13 [==========================>...] - ETA: 0s13/13 [==============================] - 2s 16ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 16ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 16ms/step
Training rmse: 0.87  and Testing rmse: 0.19 and Hold rmse: 1.74
Training R2: 0.04  and Testing R2: 0.29 and Hold R2: -0.06

---------------
ADDING TEXT ON TOP
---------------

['Be2PtCu', 'TiWMn2', 'Ru2TiGe', 'Cs2LiInBr6', 'ScTaOs2', 'Ta2VRu', 'RbI', 'ScPd2Cd', 'Rb2TiCl6', 'Fe2TiGe', 'TlPd3O4', 'YPd2In', 'TiMoTc2', 'Pd2CdIn', 'Hf2OsRh', 'Hf2IrRh', 'LiAg2Zn', 'LiTiRh2', 'BeNbRu2', 'ScCo2Ga', 'TaC', 'AuIn2', 'MgZrIr2', 'TiWTc2', 'CaS', 'Ti2ReIr', 'ScTaRu2', 'LiBePd2', 'ScH2', 'LiIrAl2', 'LiScPt2', 'ThO2', 'YPd2Cd', 'HfWTc2', 'K2PdCl6', 'Mg2RhAg', 'Sc2RuCo', 'Fe2TiSi', 'TiIr2Zn', 'YbO', 'HK1', 'PrN', 'TaRh2Cu', 'NaMgPb2', 'ThC', 'ScVRu2', 'Cs2PtBr6', 'Ti2ReRh', 'ScRh2Al', 'Sc2RuZn', 'TiTaTc2', 'LiHf2Re', 'Na2O', 'Sc2RuCu', 'YAs', 'LiZrPt2', 'ZrC', 'MgNi2Sn', 'Cu', 'TiTaOs2', 'LiPdAu2', 'Ru2TiSi', 'LiSc2Pt', 'MgTiRh2', 'Mg2RhPd', 'Ti2MnRh', 'RbF', 'V3Re', 'LiPt2Ga', 'RbCl', 'Ta2NbIr', 'MgZrAu2', 'AuGa2', 'MgIr2Si', 'LuN', 'Cs2LiLuCl6', 'Rb2PtCl6', 'LiSc2Ir', 'MgIr2Sn', 'LiNiAl2', 'TiTaRe2', 'HoH2', 'LaMg3', 'MgRh2Al', 'MgIr2Al', 'TiCo2Zn', 'MgPd2Ga', 'CaMgHg2', 'RhNiZn2', 'Sc2ZnGa', 'Ru2AlSi', 'Ti2TcRh', 'Rb2PtI6', 'ScPd2In', 'LiCo2Ge', 'ScIr2Al', 'Sc2IrCo', 'V2TcOs', 'Na2PtH6', 'BeWRu2', 'Li2PdHg', 'Ti2MoPt', 'Y2ZnAl', 'Ti2TcIr', 'LiCu2Si', 'ZrNi2In', 'Sc2AgIn', 'LiMgTl2', 'Rb2NiF6', 'Ti2MoIr', 'NiH', 'YAu2In', 'LiMg2Rh', 'Au', 'BeOs2Si', 'Cs2PtCl6', 'ScCu2Ga', 'TlBr', 'KTl2Bi', 'MgZn2Y', 'MgTiIr2', 'ScNbRu2', 'HfRh2Ga', 'TiAu2Zn', 'Ni2AlHf', 'Mg2Pb', 'ZrCu2Zn', 'Na2KSb', 'TiRh2Zn', 'Ti2TcNi', 'MgHfRh2', 'Be2RhNi', 'Y2ZnIn', 'LiPdAl2', 'ScRh2In', 'Be2CoNi', 'Li2O', 'LiNiZn2', 'LiMg2Hg', 'LiNi2Ga', 'CaO', 'Ru2HfAl', 'SnTe', 'LiWRu2', 'ScSe', 'Na2S', 'Cs2PtF6', 'Ti2TcOs', 'Be2RuPt', 'LiScAu2', 'Mg2AuAg', 'Sc2PtNi', 'Ni2AlTi', 'CaF2', 'Rh2TiGa', 'LiRh2Al', 'LiPtIn2', 'ScS', 'YPd2Sn', 'LiPd2Hg', 'Pd2HfIn', 'LiMg2Pt', 'LiAu2Zn', 'BaS', 'Li2NaSb', 'Hf2ReCo', 'Th2BiTe', 'AlCu2Sc', 'ScNi2Sn', 'Ta2WOs', 'Mg3Nd', 'PtGa2', 'HfCu2Zn', 'LiCu2Ge', 'Be2RhPt', 'ReMn2Al', 'LiPtGa2', 'Sc2RuGa', 'LiSc2Rh', 'NbOs2Al', 'BeTiIr2', 'RhAuZn2', 'Sc2OsCu', 'LiPd2Zn', 'YSb', 'TiOs2Si', 'ScBi', 'LiNbRh2', 'Rb2PdBr6', 'Sc2IrCu', 'MgRh2Sn', 'LiBePt2', 'MgAg2Al', 'Ag2MgCd', 'Rh2CdTl', 'Ca2PdAu', 'V2ReOs', 'Ca2MgTl', 'MgAg2Ga', 'MgSc2Al', 'Ba2AuSb', 'NiSi2', 'PdAuCu2', 'Rb2PbCl6', 'Sc2CuGa', 'Cs2PtH6', 'BeIr2Al', 'Kr', 'MgHfIr2', 'PtSn2', 'RuCoAl2', 'AlCu2Hf', 'Cs2TeI6', 'YAu2Cd', 'MgZrPd2', 'BeCo2Si', 'LiHfPt2', 'Li2Se', 'AgCl', 'ScB12', 'BeTiRh2', 'Rb2PdCl6', 'Y2RuPd', 'V2CrRe', 'ScHfRu2', 'MgY2Al', 'LiPdHg2', 'Ru2AlTa', 'Co2ScAl', 'BeCo2Ge', 'LaAs', 'Y2RuZn', 'TaRh2Zn', 'LiCa2Al', 'MgSc2Cd', 'ScRh2Cd', 'Ru2VAl', 'LiIrZn2', 'Ag2MgZn', 'LiPdIn2', 'YN', 'V3Os', 'Be2TiIr', 'TiVTc2', 'CuPt7', 'Be2IrPd', 'MgRh2Ga', 'TiReTc2', 'ScAu2In', 'ScPd2Ga', 'Be2CoPt', 'BaF2', 'Ti2TcRu', 'ScRh2Zn', 'LiPt2In', 'Sc2PtCu', 'CsF', 'ScHfRh2', 'AlNi2Zr', 'NbTc2Si', 'K2PtCl6', 'ZrCu2Cd', 'Pd2TiGa', 'LiZr2Tc', 'ZrPd2Cd', 'LiNi2Sn', 'Cs2ZrCl6', 'Na2TlBi', 'LiMg2Zn', 'ScN', 'KF', 'PbS', 'TiRu2Ga', 'ScCu2In', 'Pb', 'Sc2AgTl', 'Mg2PtAg', 'Sc2AgHg', 'MgPd2Al', 'LiCu2Ga', 'BeNi2Si', 'HfN', 'LiRhAl2', 'TaFe2Ga', 'Cs2SnBr6', 'Sc2IrPd', 'TiTc2Sb', 'CdF2', 'TaOs2Al', 'Rh2SnCu', 'MgRh2Si', 'Pd2AgCd', 'Na2Se', 'Be2RhCu', 'LiMg2Ag', 'MgO', 'Mg2RhAu', 'TbAs', 'LaS', 'MgScRh2', 'ZrRh2Sn', 'TiTaRu2', 'MgTaIr2', 'Ne', 'Ir2ZnAl', 'Zr2OsCu', 'K2Se', 'IK1', 'Rh2TiAl', 'Pd2AgHg', 'Sc2ZnAl', 'LiPd2Si', 'PbTe', 'K2O', 'TiWRe2', 'Be2PtPd', 'Sc2OsPd', 'Li3Bi', 'MgTaRu2', 'HfNbTc2', 'LiNi2Si', 'NaI', 'LiHfRh2', 'Ca2MgIn', 'LiPtZn2', 'Ti2OsRu', 'Hf2ReZn', 'ScNbTc2', 'MgTaRh2', 'TiNbRe2', 'Be2IrCu', 'Pd2AuIn', 'LiNi2Al', 'LiPdCd2', 'Rb2S', 'LiPd2Sb', 'NaPd2Hg', 'UC1', 'Sc2AuZn', 'HfC', 'Mg2Si', 'LiSc2Tc', 'BaCl2', 'LiPd2Cd', 'LiH', 'Ti2MoAl', 'VTc2Si', 'Y2IrPd', 'Sc2IrZn', 'Sc2RuPt', 'HfNi2Zn', 'SrF2', 'Cs2Se', 'Ru2AlGe', 'K2PtH6', 'Na2TlSb', 'Li2PdTl', 'AgF', 'Sc2OsNi', 'Hf2TcRh', 'PtIn2', 'Be2IrPt', 'DyH2', 'LiPd2As', 'BeVOs2', 'Sc2OsGa', 'Ta2NbRu', 'ScNbOs2', 'ScP', 'ScAg2Cd', 'TlI', 'Sc2OsZn', 'SnSb', 'Cs2PtI6', 'Pd2TiSn', 'Ti2TcPt', 'Ti2Rh6B', 'Mg2FeH6', 'Pd2HfAl', 'Au2CuAl', 'K2NiF6', 'YBa2NbO6', 'MgRh2Tl', 'KCl', 'MgIr2Ga', 'Rb2Se', 'Ti2ReZn', 'LiZr2Os', 'NaBr', 'ScIr2In', 'CsBr', 'OsIrAl2', 'Ta2NbOs', 'SrO', 'Li2S', 'ScNi2Ga', 'LiY2Al', 'CsCl', 'ScIr2Ga', 'LiVIr2', 'YHg2Cd', 'MgZrRh2', 'V3Ru', 'SrS', 'Rb2PdF6', 'ScAg2Al', 'LiHfIr2', 'MgS', '(Tl)2PtCl6', 'Sc2RuRh', 'PtAl2', 'TaRu2Zn', 'BeRh2Al', 'Li2PdCd', 'YAu2Mg', 'Mg2PtPd', 'Ru2TiSn', 'Y2RuCu', 'PbSe', 'TiOs2Al', 'Hf2ReIr', 'PaC', 'Cs2HfI6', 'PbF2', 'ScHfOs2', 'Pd2TiAl', 'LiPtAl2', 'MgYCd2', 'Sc2RuAg', 'Ir', 'Al2Cu', 'Ru2VGa', 'SmS', 'SrCl2', 'Ti2AlRe', 'ZrN', 'LiPdZn2', 'MgRh2Ge', 'LiPd2Cu', 'LiPt7', 'ScPd2Al', 'VTc2Ge', 'RhPdZn2', 'LiCu2Al', 'LiZrIr2', 'MgTaOs2', 'IrSn2', 'Rb2ZrCl6', 'Sc2OsAg', 'MgYHg2', 'RhPtCd2', 'ScSb', 'Cs2TiCl6', 'LiZrAu2', 'TiCu2In', 'RuPtAl2', 'BaSe', 'KBr', 'YAg2Mg', 'Sc2RuIr', 'ScRu2Sb', 'MgHfPd2', 'TiPd2Zn', 'VTc2Ga', 'LiPdGa2', 'HfCu2In', 'Fe2Ta(Al)', 'Sc2PtZn', 'Rh', 'Sc2OsAl', 'Be2C', 'Sc2RuPd', 'Ni2TiGa', 'Mg2OsH6', 'AuAl2', 'TiN', 'NaPtCd2', 'TiC', 'ScAg2In', 'CaTe', 'Ti2ReNi', 'Pd2CuZn', 'CaTiF6', 'MgNi2Ga', 'CeO2', 'Rb2PtH6', 'ScPd2Sn', 'MgSc2Tl', 'NaTl2Bi', 'VRu2Zn', 'ScPt2In', 'Fe2VGa', 'LiHfPd2', 'Sc2TcAl', 'ScAu2Al', 'LiPd2In', 'Rh2CuGe', 'Ru2TiAl', 'K2S', 'ZrAu2Al', 'NbRu2In', 'YbTe', 'ScCu2Zn', 'LiPtCd2', 'Sc2OsPt', 'MgNi2In', 'AuAgZn2', 'Ti2RePd', 'Li3Hg', 'Ar', 'Fe2VAl', 'Cu2TiZn', 'Be2RhPd', 'K2PtBr6', 'LiAg2Ge', 'ScRu2Sn', 'SrSe', 'ScPt2Zn', 'Mg2RhPt', 'LiAu2Al', 'Ti2MoNi', 'ErH2', 'RuPdAl2', 'LiNi2Ge', 'AlNi2Sc', 'Sc2RuNi', 'Li3Au', 'RbBr', 'RhPdCd2', 'Cs2GeCl6', 'Pd2ZrAl', 'NaF', 'ThN', 'CdO', 'Li2CdSn', 'LiAlAg2', 'Cs2PbCl6', 'HfIr2Zn', 'ErAs', 'BeTiCo2', 'TiNi2Zn', 'Hf2TcRu', 'LiF', 'HfRu2Ga', 'NaPd2Tl', 'VOs2Al', 'Ru2HfSn', 'LiCo2Si', 'NbRu2Al', 'Mg2RuH6', 'Al', 'CaMgTl2', 'ScRh2Ga', 'CsI', 'LiScTl2', 'ScNi2In', 'Sr2AuSb', 'NaH', 'RuIrAl2', 'NbH2', 'HfAu2Zn', 'MgPd2In', 'K2TiCl6', 'HfRu2Si', 'Fe2NbAl', 'LiHf2Os', 'Hf2MoRh', 'Sc2PtPd', 'ScRh2Tl', 'AlCu2Ti', 'LiPd2Ge', 'LiPd2Al', 'Mg2Sn', 'Ti2TcAl', 'LiRhZn2', 'ZrCu2In', 'BaTe', 'YMg3', 'BaO', 'Cs2SnI6', 'CoSi2', 'VH2', 'LiPt2Al', 'Ti2TcPd', 'Mg2Ge', 'LiTiIr2', 'Y2IrRh', 'NaCl', 'ScHg2Cd', 'LiSc2Ru', 'LiPd2Pb', 'Fe2TiSn']
The length of training, testing, and holdout dataset is:
 images, 414 89 89 
 text, 414 89 89 respectively
Training fold 1...
0.0007
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 my_image_model_headless (Funct  (None, 256)         24564256    ['input_3[0][0]']                
 ional)                                                                                           
                                                                                                  
 my_text_model_headless (Functi  (None, 256)         125438464   ['input_3[0][0]',                
 onal)                                                            'input_ids[0][0]',              
                                                                  'attention_mask[0][0]']         
                                                                                                  
 concat_both (Concatenate)      (None, 512)          0           ['my_image_model_headless[0][0]',
                                                                  'my_text_model_headless[0][0]'] 
                                                                                                  
 dense_1_both (Dense)           (None, 512)          262656      ['concat_both[0][0]']            
                                                                                                  
 bn_1_both (BatchNormalization)  (None, 512)         2048        ['dense_1_both[0][0]']           
                                                                                                  
 dropout_1_both (Dropout)       (None, 512)          0           ['bn_1_both[0][0]']              
                                                                                                  
 dense_2_both (Dense)           (None, 256)          131328      ['dropout_1_both[0][0]']         
                                                                                                  
 bn_2_both (BatchNormalization)  (None, 256)         1024        ['dense_2_both[0][0]']           
                                                                                                  
 dropout_2_both (Dropout)       (None, 256)          0           ['bn_2_both[0][0]']              
                                                                                                  
 dense_3_both (Dense)           (None, 1)            257         ['dropout_2_both[0][0]']         
                                                                                                  
==================================================================================================
Total params: 150,400,033
Trainable params: 395,777
Non-trainable params: 150,004,256
__________________________________________________________________________________________________
None

Search: Running Trial #1

Value             |Best Value So Far |Hyperparameter
0.0007            |0.0007            |learning_rate

0.0007
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 my_image_model_headless (Funct  (None, 256)         24564256    ['input_1[0][0]']                
 ional)                                                                                           
                                                                                                  
 my_text_model_headless (Functi  (None, 256)         125438464   ['input_1[0][0]',                
 onal)                                                            'input_ids[0][0]',              
                                                                  'attention_mask[0][0]']         
                                                                                                  
 concat_both (Concatenate)      (None, 512)          0           ['my_image_model_headless[1][0]',
                                                                  'my_text_model_headless[1][0]'] 
                                                                                                  
 dense_1_both (Dense)           (None, 512)          262656      ['concat_both[0][0]']            
                                                                                                  
 bn_1_both (BatchNormalization)  (None, 512)         2048        ['dense_1_both[0][0]']           
                                                                                                  
 dropout_1_both (Dropout)       (None, 512)          0           ['bn_1_both[0][0]']              
                                                                                                  
 dense_2_both (Dense)           (None, 256)          131328      ['dropout_1_both[0][0]']         
                                                                                                  
 bn_2_both (BatchNormalization)  (None, 256)         1024        ['dense_2_both[0][0]']           
                                                                                                  
 dropout_2_both (Dropout)       (None, 256)          0           ['bn_2_both[0][0]']              
                                                                                                  
 dense_3_both (Dense)           (None, 1)            257         ['dropout_2_both[0][0]']         
                                                                                                  
==================================================================================================
Total params: 150,400,033
Trainable params: 395,777
Non-trainable params: 150,004,256
__________________________________________________________________________________________________
None
 1/11 [=>............................] - ETA: 1:39 - loss: 1.3732 3/11 [=======>......................] - ETA: 0s - loss: 2.6878   5/11 [============>.................] - ETA: 0s - loss: 2.3715 7/11 [==================>...........] - ETA: 0s - loss: 2.7290 9/11 [=======================>......] - ETA: 0s - loss: 2.438711/11 [==============================] - ETA: 0s - loss: 2.434311/11 [==============================] - 21s 1s/step - loss: 2.4343 - val_loss: 4.0630
[2K[2KTrial 1 Complete [00h 00m 24s]
val_loss: 4.063003063201904

Best val_loss So Far: 4.063003063201904
Total elapsed time: 00h 00m 24s
Best Learning Rate for fold 1 : 0.0007
0.0007
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 my_image_model_headless (Funct  (None, 256)         24564256    ['input_2[0][0]']                
 ional)                                                                                           
                                                                                                  
 my_text_model_headless (Functi  (None, 256)         125438464   ['input_2[0][0]',                
 onal)                                                            'input_ids[0][0]',              
                                                                  'attention_mask[0][0]']         
                                                                                                  
 concat_both (Concatenate)      (None, 512)          0           ['my_image_model_headless[2][0]',
                                                                  'my_text_model_headless[2][0]'] 
                                                                                                  
 dense_1_both (Dense)           (None, 512)          262656      ['concat_both[0][0]']            
                                                                                                  
 bn_1_both (BatchNormalization)  (None, 512)         2048        ['dense_1_both[0][0]']           
                                                                                                  
 dropout_1_both (Dropout)       (None, 512)          0           ['bn_1_both[0][0]']              
                                                                                                  
 dense_2_both (Dense)           (None, 256)          131328      ['dropout_1_both[0][0]']         
                                                                                                  
 bn_2_both (BatchNormalization)  (None, 256)         1024        ['dense_2_both[0][0]']           
                                                                                                  
 dropout_2_both (Dropout)       (None, 256)          0           ['bn_2_both[0][0]']              
                                                                                                  
 dense_3_both (Dense)           (None, 1)            257         ['dropout_2_both[0][0]']         
                                                                                                  
==================================================================================================
Total params: 150,400,033
Trainable params: 395,777
Non-trainable params: 150,004,256
__________________________________________________________________________________________________
None
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 186, 186, 3  0           []                               
                                )]                                                                
                                                                                                  
 input_ids (InputLayer)         [(None, 11)]         0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 11)]         0           []                               
                                                                                                  
 my_image_model_headless (Funct  (None, 256)         24564256    ['input_2[0][0]']                
 ional)                                                                                           
                                                                                                  
 my_text_model_headless (Functi  (None, 256)         125438464   ['input_2[0][0]',                
 onal)                                                            'input_ids[0][0]',              
                                                                  'attention_mask[0][0]']         
                                                                                                  
 concat_both (Concatenate)      (None, 512)          0           ['my_image_model_headless[2][0]',
                                                                  'my_text_model_headless[2][0]'] 
                                                                                                  
 dense_1_both (Dense)           (None, 512)          262656      ['concat_both[0][0]']            
                                                                                                  
 bn_1_both (BatchNormalization)  (None, 512)         2048        ['dense_1_both[0][0]']           
                                                                                                  
 dropout_1_both (Dropout)       (None, 512)          0           ['bn_1_both[0][0]']              
                                                                                                  
 dense_2_both (Dense)           (None, 256)          131328      ['dropout_1_both[0][0]']         
                                                                                                  
 bn_2_both (BatchNormalization)  (None, 256)         1024        ['dense_2_both[0][0]']           
                                                                                                  
 dropout_2_both (Dropout)       (None, 256)          0           ['bn_2_both[0][0]']              
                                                                                                  
 dense_3_both (Dense)           (None, 1)            257         ['dropout_2_both[0][0]']         
                                                                                                  
==================================================================================================
Total params: 150,400,033
Trainable params: 395,777
Non-trainable params: 150,004,256
__________________________________________________________________________________________________
FINAL MODEL: None
Epoch 1/700
 1/11 [=>............................] - ETA: 1:38 - loss: 2.9234 3/11 [=======>......................] - ETA: 0s - loss: 2.6958   5/11 [============>.................] - ETA: 0s - loss: 2.5665 7/11 [==================>...........] - ETA: 0s - loss: 2.2411 9/11 [=======================>......] - ETA: 0s - loss: 2.263211/11 [==============================] - ETA: 0s - loss: 2.1616
Epoch 1: val_loss improved from inf to 4.39034, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 22s 1s/step - loss: 2.1616 - val_loss: 4.3903
Epoch 2/700
 1/11 [=>............................] - ETA: 0s - loss: 1.1811 3/11 [=======>......................] - ETA: 0s - loss: 1.6095 5/11 [============>.................] - ETA: 0s - loss: 1.5915 7/11 [==================>...........] - ETA: 0s - loss: 1.5127 9/11 [=======================>......] - ETA: 0s - loss: 1.402511/11 [==============================] - ETA: 0s - loss: 1.3519
Epoch 2: val_loss improved from 4.39034 to 4.30514, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 7s 720ms/step - loss: 1.3519 - val_loss: 4.3051
Epoch 3/700
 1/11 [=>............................] - ETA: 0s - loss: 1.1206 3/11 [=======>......................] - ETA: 0s - loss: 0.9875 5/11 [============>.................] - ETA: 0s - loss: 0.9970 7/11 [==================>...........] - ETA: 0s - loss: 1.0613 9/11 [=======================>......] - ETA: 0s - loss: 1.038111/11 [==============================] - ETA: 0s - loss: 1.0039
Epoch 3: val_loss improved from 4.30514 to 4.13967, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 7s 726ms/step - loss: 1.0039 - val_loss: 4.1397
Epoch 4/700
 1/11 [=>............................] - ETA: 0s - loss: 0.5879 3/11 [=======>......................] - ETA: 0s - loss: 0.6590 5/11 [============>.................] - ETA: 0s - loss: 0.8181 7/11 [==================>...........] - ETA: 0s - loss: 0.8714 9/11 [=======================>......] - ETA: 0s - loss: 0.799911/11 [==============================] - ETA: 0s - loss: 0.7686
Epoch 4: val_loss did not improve from 4.13967
11/11 [==============================] - 0s 40ms/step - loss: 0.7686 - val_loss: 4.4991
Epoch 5/700
 1/11 [=>............................] - ETA: 0s - loss: 0.6559 3/11 [=======>......................] - ETA: 0s - loss: 0.7068 5/11 [============>.................] - ETA: 0s - loss: 0.6401 7/11 [==================>...........] - ETA: 0s - loss: 0.6429 9/11 [=======================>......] - ETA: 0s - loss: 0.658011/11 [==============================] - ETA: 0s - loss: 0.6155
Epoch 5: val_loss did not improve from 4.13967
11/11 [==============================] - 0s 37ms/step - loss: 0.6155 - val_loss: 4.1513
Epoch 6/700
 1/11 [=>............................] - ETA: 0s - loss: 0.8310 3/11 [=======>......................] - ETA: 0s - loss: 0.6281 5/11 [============>.................] - ETA: 0s - loss: 0.6203 7/11 [==================>...........] - ETA: 0s - loss: 0.5772 9/11 [=======================>......] - ETA: 0s - loss: 0.544811/11 [==============================] - ETA: 0s - loss: 0.5243
Epoch 6: val_loss improved from 4.13967 to 4.09455, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 8s 835ms/step - loss: 0.5243 - val_loss: 4.0946
Epoch 7/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3659 3/11 [=======>......................] - ETA: 0s - loss: 0.4190 5/11 [============>.................] - ETA: 0s - loss: 0.4413 7/11 [==================>...........] - ETA: 0s - loss: 0.4680 9/11 [=======================>......] - ETA: 0s - loss: 0.480811/11 [==============================] - ETA: 0s - loss: 0.4720
Epoch 7: val_loss improved from 4.09455 to 3.75387, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/KFold/fold_0.hdf5
11/11 [==============================] - 7s 717ms/step - loss: 0.4720 - val_loss: 3.7539
Epoch 8/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3454 3/11 [=======>......................] - ETA: 0s - loss: 0.4050 5/11 [============>.................] - ETA: 0s - loss: 0.3738 7/11 [==================>...........] - ETA: 0s - loss: 0.3805 9/11 [=======================>......] - ETA: 0s - loss: 0.410111/11 [==============================] - ETA: 0s - loss: 0.4053
Epoch 8: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 39ms/step - loss: 0.4053 - val_loss: 4.0691
Epoch 9/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2703 3/11 [=======>......................] - ETA: 0s - loss: 0.4120 5/11 [============>.................] - ETA: 0s - loss: 0.3471 7/11 [==================>...........] - ETA: 0s - loss: 0.3582 9/11 [=======================>......] - ETA: 0s - loss: 0.372611/11 [==============================] - ETA: 0s - loss: 0.3662
Epoch 9: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 39ms/step - loss: 0.3662 - val_loss: 3.7949
Epoch 10/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1932 3/11 [=======>......................] - ETA: 0s - loss: 0.3219 5/11 [============>.................] - ETA: 0s - loss: 0.3617 7/11 [==================>...........] - ETA: 0s - loss: 0.3730 9/11 [=======================>......] - ETA: 0s - loss: 0.381211/11 [==============================] - ETA: 0s - loss: 0.3983
Epoch 10: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 37ms/step - loss: 0.3983 - val_loss: 4.0709
Epoch 11/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4580 3/11 [=======>......................] - ETA: 0s - loss: 0.3582 5/11 [============>.................] - ETA: 0s - loss: 0.3760 7/11 [==================>...........] - ETA: 0s - loss: 0.4370 9/11 [=======================>......] - ETA: 0s - loss: 0.413311/11 [==============================] - ETA: 0s - loss: 0.3919
Epoch 11: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 37ms/step - loss: 0.3919 - val_loss: 4.0662
Epoch 12/700
 1/11 [=>............................] - ETA: 0s - loss: 0.5645 3/11 [=======>......................] - ETA: 0s - loss: 0.4466 5/11 [============>.................] - ETA: 0s - loss: 0.3941 7/11 [==================>...........] - ETA: 0s - loss: 0.3523 9/11 [=======================>......] - ETA: 0s - loss: 0.381911/11 [==============================] - ETA: 0s - loss: 0.3626
Epoch 12: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 37ms/step - loss: 0.3626 - val_loss: 4.1868
Epoch 13/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2995 3/11 [=======>......................] - ETA: 0s - loss: 0.3755 5/11 [============>.................] - ETA: 0s - loss: 0.3208 7/11 [==================>...........] - ETA: 0s - loss: 0.3202 9/11 [=======================>......] - ETA: 0s - loss: 0.318211/11 [==============================] - ETA: 0s - loss: 0.3422
Epoch 13: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 37ms/step - loss: 0.3422 - val_loss: 4.0621
Epoch 14/700
 1/11 [=>............................] - ETA: 0s - loss: 0.4967 3/11 [=======>......................] - ETA: 0s - loss: 0.3498 5/11 [============>.................] - ETA: 0s - loss: 0.3235 7/11 [==================>...........] - ETA: 0s - loss: 0.3037 9/11 [=======================>......] - ETA: 0s - loss: 0.289311/11 [==============================] - ETA: 0s - loss: 0.2984
Epoch 14: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 37ms/step - loss: 0.2984 - val_loss: 4.2236
Epoch 15/700
 1/11 [=>............................] - ETA: 0s - loss: 0.1888 3/11 [=======>......................] - ETA: 0s - loss: 0.2265 5/11 [============>.................] - ETA: 0s - loss: 0.2678 7/11 [==================>...........] - ETA: 0s - loss: 0.2931 9/11 [=======================>......] - ETA: 0s - loss: 0.310011/11 [==============================] - ETA: 0s - loss: 0.3150
Epoch 15: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3150 - val_loss: 4.0557
Epoch 16/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2326 3/11 [=======>......................] - ETA: 0s - loss: 0.3694 5/11 [============>.................] - ETA: 0s - loss: 0.3784 7/11 [==================>...........] - ETA: 0s - loss: 0.3451 9/11 [=======================>......] - ETA: 0s - loss: 0.328811/11 [==============================] - ETA: 0s - loss: 0.3373
Epoch 16: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3373 - val_loss: 4.0039
Epoch 17/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2770 3/11 [=======>......................] - ETA: 0s - loss: 0.3515 5/11 [============>.................] - ETA: 0s - loss: 0.3464 7/11 [==================>...........] - ETA: 0s - loss: 0.3518 9/11 [=======================>......] - ETA: 0s - loss: 0.335911/11 [==============================] - ETA: 0s - loss: 0.3266
Epoch 17: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3266 - val_loss: 3.9228
Epoch 18/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2640 3/11 [=======>......................] - ETA: 0s - loss: 0.3307 5/11 [============>.................] - ETA: 0s - loss: 0.3115 7/11 [==================>...........] - ETA: 0s - loss: 0.2954 9/11 [=======================>......] - ETA: 0s - loss: 0.307911/11 [==============================] - ETA: 0s - loss: 0.3018
Epoch 18: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3018 - val_loss: 4.0077
Epoch 19/700
 1/11 [=>............................] - ETA: 0s - loss: 0.5603 3/11 [=======>......................] - ETA: 0s - loss: 0.4410 5/11 [============>.................] - ETA: 0s - loss: 0.3729 7/11 [==================>...........] - ETA: 0s - loss: 0.3469 9/11 [=======================>......] - ETA: 0s - loss: 0.359611/11 [==============================] - ETA: 0s - loss: 0.3713
Epoch 19: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3713 - val_loss: 3.8855
Epoch 20/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2696 3/11 [=======>......................] - ETA: 0s - loss: 0.2907 5/11 [============>.................] - ETA: 0s - loss: 0.3331 7/11 [==================>...........] - ETA: 0s - loss: 0.3236 9/11 [=======================>......] - ETA: 0s - loss: 0.321211/11 [==============================] - ETA: 0s - loss: 0.3291
Epoch 20: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.3291 - val_loss: 3.9107
Epoch 21/700
 1/11 [=>............................] - ETA: 0s - loss: 0.2762 3/11 [=======>......................] - ETA: 0s - loss: 0.2155 5/11 [============>.................] - ETA: 0s - loss: 0.2335 7/11 [==================>...........] - ETA: 0s - loss: 0.2266 9/11 [=======================>......] - ETA: 0s - loss: 0.214411/11 [==============================] - ETA: 0s - loss: 0.2369
Epoch 21: val_loss did not improve from 3.75387
11/11 [==============================] - 0s 38ms/step - loss: 0.2369 - val_loss: 3.8654
Epoch 22/700
 1/11 [=>............................] - ETA: 0s - loss: 0.3620 3/11 [=======>......................] - ETA: 0s - loss: 0.2586 5/11 [============>.................] - ETA: 0s - loss: 0.2431 7/11 [==================>...........] - ETA: 0s - loss: 0.2646 9/11 [=======================>......] - ETA: 0s - loss: 0.287911/11 [==============================] - ETA: 0s - loss: 0.2779
Epoch 22: val_loss did not improve from 3.75387
11/11 [==============================] - 1s 82ms/step - loss: 0.2779 - val_loss: 3.8600
1/3 [=========>....................] - ETA: 5s - loss: 0.24993/3 [==============================] - ETA: 0s - loss: 3.20273/3 [==============================] - 3s 27ms/step - loss: 3.2027
Fold 1 Loss: 3.2026760578155518
Average Loss: 3.2026760578155518

PERFORMANCES of the pretrained model, no fine-tuning

1/3 [=========>....................] - ETA: 0s - loss: 0.26093/3 [==============================] - ETA: 0s - loss: 0.23153/3 [==============================] - 0s 28ms/step - loss: 0.2315
1/3 [=========>....................] - ETA: 5s3/3 [==============================] - ETA: 0s3/3 [==============================] - 3s 28ms/step
Test Loss (MSE): 0.23154586553573608
Mean Squared Error (MSE): 0.23154588
Mean Absolute Error (MAE): 0.4132524
R-squared (R2) Score: -3.4541196015391247
 1/13 [=>............................] - ETA: 0s 3/13 [=====>........................] - ETA: 0s 5/13 [==========>...................] - ETA: 0s 7/13 [===============>..............] - ETA: 0s 9/13 [===================>..........] - ETA: 0s11/13 [========================>.....] - ETA: 0s13/13 [==============================] - ETA: 0s13/13 [==============================] - 0s 27ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 25ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - 0s 24ms/step
!! Training rmse: 0.94  and Testing rmse: 0.48 and Hold rmse: 1.79
Training R2: -0.12  and Testing R2: -3.45 and Hold R2: -0.12

____________
FINE-TUNING
____________

Epoch 1/700
 1/13 [=>............................] - ETA: 2:34 - loss: 0.3028 3/13 [=====>........................] - ETA: 0s - loss: 0.3358   5/13 [==========>...................] - ETA: 0s - loss: 0.3488 7/13 [===============>..............] - ETA: 0s - loss: 1.6547 9/13 [===================>..........] - ETA: 0s - loss: 1.383611/13 [========================>.....] - ETA: 0s - loss: 1.216913/13 [==============================] - ETA: 0s - loss: 1.0860
Epoch 1: val_loss improved from inf to 0.17565, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 37s 2s/step - loss: 1.0860 - val_loss: 0.1757
Epoch 2/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4934 3/13 [=====>........................] - ETA: 0s - loss: 0.5847 5/13 [==========>...................] - ETA: 0s - loss: 0.4728 7/13 [===============>..............] - ETA: 0s - loss: 0.4290 9/13 [===================>..........] - ETA: 0s - loss: 0.435911/13 [========================>.....] - ETA: 0s - loss: 0.460813/13 [==============================] - ETA: 0s - loss: 1.1605
Epoch 2: val_loss improved from 0.17565 to 0.17352, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 19s 2s/step - loss: 1.1605 - val_loss: 0.1735
Epoch 3/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3474 3/13 [=====>........................] - ETA: 0s - loss: 0.6207 5/13 [==========>...................] - ETA: 0s - loss: 0.5107 7/13 [===============>..............] - ETA: 0s - loss: 0.5034 9/13 [===================>..........] - ETA: 0s - loss: 1.359111/13 [========================>.....] - ETA: 0s - loss: 1.172113/13 [==============================] - ETA: 0s - loss: 1.0486
Epoch 3: val_loss improved from 0.17352 to 0.13754, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 18s 1s/step - loss: 1.0486 - val_loss: 0.1375
Epoch 4/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3468 3/13 [=====>........................] - ETA: 0s - loss: 0.3258 5/13 [==========>...................] - ETA: 0s - loss: 0.3801 7/13 [===============>..............] - ETA: 0s - loss: 1.6426 9/13 [===================>..........] - ETA: 0s - loss: 1.382411/13 [========================>.....] - ETA: 0s - loss: 1.178913/13 [==============================] - ETA: 0s - loss: 1.0750
Epoch 4: val_loss did not improve from 0.13754
13/13 [==============================] - 1s 53ms/step - loss: 1.0750 - val_loss: 0.1455
Epoch 5/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3183 3/13 [=====>........................] - ETA: 0s - loss: 0.3642 5/13 [==========>...................] - ETA: 0s - loss: 0.3337 7/13 [===============>..............] - ETA: 0s - loss: 0.3565 9/13 [===================>..........] - ETA: 0s - loss: 0.400411/13 [========================>.....] - ETA: 0s - loss: 1.101313/13 [==============================] - ETA: 0s - loss: 0.9778
Epoch 5: val_loss improved from 0.13754 to 0.13739, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 18s 1s/step - loss: 0.9778 - val_loss: 0.1374
Epoch 6/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1772 3/13 [=====>........................] - ETA: 0s - loss: 0.3678 5/13 [==========>...................] - ETA: 0s - loss: 0.3976 7/13 [===============>..............] - ETA: 0s - loss: 0.3714 9/13 [===================>..........] - ETA: 0s - loss: 0.387611/13 [========================>.....] - ETA: 0s - loss: 0.369213/13 [==============================] - ETA: 0s - loss: 0.9898
Epoch 6: val_loss did not improve from 0.13739
13/13 [==============================] - 1s 55ms/step - loss: 0.9898 - val_loss: 0.1419
Epoch 7/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2512 3/13 [=====>........................] - ETA: 0s - loss: 0.3346 5/13 [==========>...................] - ETA: 0s - loss: 0.3187 7/13 [===============>..............] - ETA: 0s - loss: 1.4808 9/13 [===================>..........] - ETA: 0s - loss: 1.224411/13 [========================>.....] - ETA: 0s - loss: 1.068113/13 [==============================] - ETA: 0s - loss: 0.9535
Epoch 7: val_loss improved from 0.13739 to 0.12642, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 19s 2s/step - loss: 0.9535 - val_loss: 0.1264
Epoch 8/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4108 3/13 [=====>........................] - ETA: 0s - loss: 0.3755 5/13 [==========>...................] - ETA: 0s - loss: 0.3375 7/13 [===============>..............] - ETA: 0s - loss: 0.3231 9/13 [===================>..........] - ETA: 0s - loss: 0.321711/13 [========================>.....] - ETA: 0s - loss: 0.357113/13 [==============================] - ETA: 0s - loss: 0.9348
Epoch 8: val_loss improved from 0.12642 to 0.12346, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 18s 1s/step - loss: 0.9348 - val_loss: 0.1235
Epoch 9/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4556 3/13 [=====>........................] - ETA: 0s - loss: 0.3513 5/13 [==========>...................] - ETA: 0s - loss: 2.0129 7/13 [===============>..............] - ETA: 0s - loss: 1.5870 9/13 [===================>..........] - ETA: 0s - loss: 1.295411/13 [========================>.....] - ETA: 0s - loss: 1.136313/13 [==============================] - ETA: 0s - loss: 1.0210
Epoch 9: val_loss did not improve from 0.12346
13/13 [==============================] - 1s 54ms/step - loss: 1.0210 - val_loss: 0.1339
Epoch 10/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3735 3/13 [=====>........................] - ETA: 0s - loss: 0.3721 5/13 [==========>...................] - ETA: 0s - loss: 1.7012 7/13 [===============>..............] - ETA: 0s - loss: 1.3310 9/13 [===================>..........] - ETA: 0s - loss: 1.098911/13 [========================>.....] - ETA: 0s - loss: 0.978713/13 [==============================] - ETA: 0s - loss: 0.8765
Epoch 10: val_loss did not improve from 0.12346
13/13 [==============================] - 1s 52ms/step - loss: 0.8765 - val_loss: 0.1297
Epoch 11/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2869 3/13 [=====>........................] - ETA: 0s - loss: 0.3413 5/13 [==========>...................] - ETA: 0s - loss: 0.3465 7/13 [===============>..............] - ETA: 0s - loss: 0.3968 9/13 [===================>..........] - ETA: 0s - loss: 0.370811/13 [========================>.....] - ETA: 0s - loss: 0.355313/13 [==============================] - ETA: 0s - loss: 0.7916
Epoch 11: val_loss improved from 0.12346 to 0.12251, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 20s 2s/step - loss: 0.7916 - val_loss: 0.1225
Epoch 12/700
 1/13 [=>............................] - ETA: 0s - loss: 6.4226 3/13 [=====>........................] - ETA: 0s - loss: 2.3177 5/13 [==========>...................] - ETA: 0s - loss: 1.5220 7/13 [===============>..............] - ETA: 0s - loss: 1.1639 9/13 [===================>..........] - ETA: 0s - loss: 0.983111/13 [========================>.....] - ETA: 0s - loss: 0.859513/13 [==============================] - ETA: 0s - loss: 0.7773
Epoch 12: val_loss did not improve from 0.12251
13/13 [==============================] - 1s 55ms/step - loss: 0.7773 - val_loss: 0.1446
Epoch 13/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3235 3/13 [=====>........................] - ETA: 0s - loss: 0.3346 5/13 [==========>...................] - ETA: 0s - loss: 1.6468 7/13 [===============>..............] - ETA: 0s - loss: 1.2769 9/13 [===================>..........] - ETA: 0s - loss: 1.089011/13 [========================>.....] - ETA: 0s - loss: 0.948013/13 [==============================] - ETA: 0s - loss: 0.8483
Epoch 13: val_loss did not improve from 0.12251
13/13 [==============================] - 1s 52ms/step - loss: 0.8483 - val_loss: 0.1458
Epoch 14/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3454 3/13 [=====>........................] - ETA: 0s - loss: 0.3126 5/13 [==========>...................] - ETA: 0s - loss: 0.3455 7/13 [===============>..............] - ETA: 0s - loss: 0.3784 9/13 [===================>..........] - ETA: 0s - loss: 0.378111/13 [========================>.....] - ETA: 0s - loss: 0.367013/13 [==============================] - ETA: 0s - loss: 0.8753
Epoch 14: val_loss improved from 0.12251 to 0.11893, saving model to results/RobertaBase_g_vrh_1_word/both/saved_models/finetuned.hdf5
13/13 [==============================] - 20s 2s/step - loss: 0.8753 - val_loss: 0.1189
Epoch 15/700
 1/13 [=>............................] - ETA: 0s - loss: 6.0222 3/13 [=====>........................] - ETA: 0s - loss: 2.2549 4/13 [========>.....................] - ETA: 0s - loss: 1.7333 6/13 [============>.................] - ETA: 0s - loss: 1.2865 8/13 [=================>............] - ETA: 0s - loss: 1.060610/13 [======================>.......] - ETA: 0s - loss: 0.896812/13 [==========================>...] - ETA: 0s - loss: 0.8227
Epoch 15: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 55ms/step - loss: 0.7963 - val_loss: 0.1238
Epoch 16/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3357 3/13 [=====>........................] - ETA: 0s - loss: 2.3418 5/13 [==========>...................] - ETA: 0s - loss: 1.5245 7/13 [===============>..............] - ETA: 0s - loss: 1.2122 9/13 [===================>..........] - ETA: 0s - loss: 1.045811/13 [========================>.....] - ETA: 0s - loss: 0.898813/13 [==============================] - ETA: 0s - loss: 0.8144
Epoch 16: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.8144 - val_loss: 0.1365
Epoch 17/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4359 3/13 [=====>........................] - ETA: 0s - loss: 0.3753 5/13 [==========>...................] - ETA: 0s - loss: 1.4229 7/13 [===============>..............] - ETA: 0s - loss: 1.0950 9/13 [===================>..........] - ETA: 0s - loss: 0.936511/13 [========================>.....] - ETA: 0s - loss: 0.830413/13 [==============================] - ETA: 0s - loss: 0.7577
Epoch 17: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.7577 - val_loss: 0.1519
Epoch 18/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3448 3/13 [=====>........................] - ETA: 0s - loss: 0.3297 5/13 [==========>...................] - ETA: 0s - loss: 0.3645 7/13 [===============>..............] - ETA: 0s - loss: 0.3425 9/13 [===================>..........] - ETA: 0s - loss: 0.334411/13 [========================>.....] - ETA: 0s - loss: 0.336813/13 [==============================] - ETA: 0s - loss: 0.6379
Epoch 18: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.6379 - val_loss: 0.1441
Epoch 19/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3382 3/13 [=====>........................] - ETA: 0s - loss: 0.3320 5/13 [==========>...................] - ETA: 0s - loss: 0.3320 7/13 [===============>..............] - ETA: 0s - loss: 0.3246 9/13 [===================>..........] - ETA: 0s - loss: 0.330111/13 [========================>.....] - ETA: 0s - loss: 0.322413/13 [==============================] - ETA: 0s - loss: 0.7046
Epoch 19: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 53ms/step - loss: 0.7046 - val_loss: 0.1271
Epoch 20/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4142 3/13 [=====>........................] - ETA: 0s - loss: 0.3381 5/13 [==========>...................] - ETA: 0s - loss: 0.3226 7/13 [===============>..............] - ETA: 0s - loss: 0.3307 9/13 [===================>..........] - ETA: 0s - loss: 0.782011/13 [========================>.....] - ETA: 0s - loss: 0.695813/13 [==============================] - ETA: 0s - loss: 0.6443
Epoch 20: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.6443 - val_loss: 0.1546
Epoch 21/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2718 3/13 [=====>........................] - ETA: 0s - loss: 0.3371 5/13 [==========>...................] - ETA: 0s - loss: 0.3399 7/13 [===============>..............] - ETA: 0s - loss: 0.9043 9/13 [===================>..........] - ETA: 0s - loss: 0.761011/13 [========================>.....] - ETA: 0s - loss: 0.675613/13 [==============================] - ETA: 0s - loss: 0.6144
Epoch 21: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.6144 - val_loss: 0.1523
Epoch 22/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2743 3/13 [=====>........................] - ETA: 0s - loss: 0.3261 5/13 [==========>...................] - ETA: 0s - loss: 0.3018 7/13 [===============>..............] - ETA: 0s - loss: 0.2947 9/13 [===================>..........] - ETA: 0s - loss: 0.797511/13 [========================>.....] - ETA: 0s - loss: 0.706613/13 [==============================] - ETA: 0s - loss: 0.6632
Epoch 22: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.6632 - val_loss: 0.1448
Epoch 23/700
 1/13 [=>............................] - ETA: 0s - loss: 0.4699 3/13 [=====>........................] - ETA: 0s - loss: 0.3635 5/13 [==========>...................] - ETA: 0s - loss: 0.3537 7/13 [===============>..............] - ETA: 0s - loss: 0.4250 9/13 [===================>..........] - ETA: 0s - loss: 0.659911/13 [========================>.....] - ETA: 0s - loss: 0.585913/13 [==============================] - ETA: 0s - loss: 0.5431
Epoch 23: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 53ms/step - loss: 0.5431 - val_loss: 0.1395
Epoch 24/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3690 3/13 [=====>........................] - ETA: 0s - loss: 0.3034 5/13 [==========>...................] - ETA: 0s - loss: 0.3378 7/13 [===============>..............] - ETA: 0s - loss: 0.3540 9/13 [===================>..........] - ETA: 0s - loss: 0.377211/13 [========================>.....] - ETA: 0s - loss: 0.643713/13 [==============================] - ETA: 0s - loss: 0.5817
Epoch 24: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 52ms/step - loss: 0.5817 - val_loss: 0.1321
Epoch 25/700
 1/13 [=>............................] - ETA: 0s - loss: 0.2720 3/13 [=====>........................] - ETA: 0s - loss: 1.1185 5/13 [==========>...................] - ETA: 0s - loss: 0.8169 7/13 [===============>..............] - ETA: 0s - loss: 0.6650 9/13 [===================>..........] - ETA: 0s - loss: 0.583711/13 [========================>.....] - ETA: 0s - loss: 0.549113/13 [==============================] - ETA: 0s - loss: 0.5150
Epoch 25: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 51ms/step - loss: 0.5150 - val_loss: 0.1477
Epoch 26/700
 1/13 [=>............................] - ETA: 0s - loss: 0.1975 3/13 [=====>........................] - ETA: 0s - loss: 0.2504 5/13 [==========>...................] - ETA: 0s - loss: 0.6986 7/13 [===============>..............] - ETA: 0s - loss: 0.5720 9/13 [===================>..........] - ETA: 0s - loss: 0.528211/13 [========================>.....] - ETA: 0s - loss: 0.502413/13 [==============================] - ETA: 0s - loss: 0.4826
Epoch 26: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 53ms/step - loss: 0.4826 - val_loss: 0.2101
Epoch 27/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3724 3/13 [=====>........................] - ETA: 0s - loss: 0.3534 5/13 [==========>...................] - ETA: 0s - loss: 0.3823 7/13 [===============>..............] - ETA: 0s - loss: 0.3721 9/13 [===================>..........] - ETA: 0s - loss: 0.376311/13 [========================>.....] - ETA: 0s - loss: 0.389513/13 [==============================] - ETA: 0s - loss: 0.5521
Epoch 27: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 53ms/step - loss: 0.5521 - val_loss: 0.1469
Epoch 28/700
 1/13 [=>............................] - ETA: 0s - loss: 0.3737 3/13 [=====>........................] - ETA: 0s - loss: 1.2420 5/13 [==========>...................] - ETA: 0s - loss: 0.8505 7/13 [===============>..............] - ETA: 0s - loss: 0.7083 9/13 [===================>..........] - ETA: 0s - loss: 0.652211/13 [========================>.....] - ETA: 0s - loss: 0.590813/13 [==============================] - ETA: 0s - loss: 0.5611
Epoch 28: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 53ms/step - loss: 0.5611 - val_loss: 0.1521
Epoch 29/700
 1/13 [=>............................] - ETA: 0s - loss: 1.8655 3/13 [=====>........................] - ETA: 0s - loss: 0.8562 5/13 [==========>...................] - ETA: 0s - loss: 0.6568 7/13 [===============>..............] - ETA: 0s - loss: 0.5573 9/13 [===================>..........] - ETA: 0s - loss: 0.510111/13 [========================>.....] - ETA: 0s - loss: 0.471313/13 [==============================] - ETA: 0s - loss: 0.4693
Epoch 29: val_loss did not improve from 0.11893
13/13 [==============================] - 1s 80ms/step - loss: 0.4693 - val_loss: 0.1520
!!!THE FINAL RESULTS FOR IMAGE AND TEXT AFTER FT :
 1/13 [=>............................] - ETA: 35s 3/13 [=====>........................] - ETA: 0s  5/13 [==========>...................] - ETA: 0s 7/13 [===============>..............] - ETA: 0s 9/13 [===================>..........] - ETA: 0s11/13 [========================>.....] - ETA: 0s13/13 [==============================] - ETA: 0s13/13 [==============================] - 3s 28ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - ETA: 0s3/3 [==============================] - 0s 26ms/step
1/3 [=========>....................] - ETA: 0s3/3 [==============================] - ETA: 0s3/3 [==============================] - 0s 26ms/step
Training rmse: 0.71  and Testing rmse: 0.34 and Hold rmse: 1.74
Training R2: 0.36  and Testing R2: -1.29 and Hold R2: -0.05
